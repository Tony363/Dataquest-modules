{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAU</td>\n",
       "      <td>05-Sep-2019</td>\n",
       "      <td>15.35</td>\n",
       "      <td>15.3500</td>\n",
       "      <td>15.0600</td>\n",
       "      <td>15.1550</td>\n",
       "      <td>162700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AADR</td>\n",
       "      <td>05-Sep-2019</td>\n",
       "      <td>50.14</td>\n",
       "      <td>50.1400</td>\n",
       "      <td>49.8300</td>\n",
       "      <td>49.9600</td>\n",
       "      <td>8500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAMC</td>\n",
       "      <td>05-Sep-2019</td>\n",
       "      <td>10.70</td>\n",
       "      <td>10.9550</td>\n",
       "      <td>10.7000</td>\n",
       "      <td>10.7000</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAU</td>\n",
       "      <td>05-Sep-2019</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.7301</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.6701</td>\n",
       "      <td>704900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACES</td>\n",
       "      <td>05-Sep-2019</td>\n",
       "      <td>31.05</td>\n",
       "      <td>31.0700</td>\n",
       "      <td>30.7164</td>\n",
       "      <td>30.8064</td>\n",
       "      <td>11100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock         date   open     high      low    close  volume  dividends\n",
       "0  AAAU  05-Sep-2019  15.35  15.3500  15.0600  15.1550  162700        NaN\n",
       "1  AADR  05-Sep-2019  50.14  50.1400  49.8300  49.9600    8500        NaN\n",
       "2  AAMC  05-Sep-2019  10.70  10.9550  10.7000  10.7000    2000        NaN\n",
       "3   AAU  05-Sep-2019   0.72   0.7301   0.6400   0.6701  704900        NaN\n",
       "4  ACES  05-Sep-2019  31.05  31.0700  30.7164  30.8064   11100        NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "path = r'/home/tony/Downloads/AMEX_20190905.csv'\n",
    "\n",
    "df = pd.read_csv(path,names=['stock','date','open','high','low','close','volume','dividends'])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:10,'stock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/tony/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  if sys.path[0] == '':\n",
      "/home/tony/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/ipykernel_launcher.py:13: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  del sys.path[0]\n",
      "/home/tony/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/ipykernel_launcher.py:14: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  \n",
      "/home/tony/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "data = []\n",
    "\n",
    "for i,stock in enumerate(df):\n",
    "    names = yf.Ticker(stock)\n",
    "    history = names.history(start='2003-01-01',end='2020-02-01')\n",
    "\n",
    "    names = pd.DataFrame(history)\n",
    "    names['PCT_Change_Close'] =  names.Close.pct_change()\n",
    "    names['PCT_Change_Low'] = names.Low.pct_change()\n",
    "    names['PCT_Change_Open'] = names.Open.pct_change()\n",
    "    names['PCT_Change_High'] = names.High.pct_change()\n",
    "    names['PCT_Change_Vol'] = names.Volume.pct_change()\n",
    "    names['Stock'] = stock\n",
    "   \n",
    "    names.drop(names.index[0],inplace=True)\n",
    "    names = names.reset_index()\n",
    "   \n",
    "    names = names[['Stock','PCT_Change_Close','PCT_Change_Open','PCT_Change_Low','PCT_Change_High','PCT_Change_Vol','Date']]\n",
    "\n",
    "    matrix = []\n",
    "    for i in range(100):\n",
    "\n",
    "        days = names.PCT_Change_Close.shift(-i)\n",
    "        df = pd.DataFrame({f'Days {i}':days.values})\n",
    "        # print(df)\n",
    "        \n",
    "        matrix.append(df)\n",
    "    matrix = pd.concat(matrix,axis=1)\n",
    "    matrix.insert(loc=0, column='Stock', value=stock)\n",
    "    data.append(matrix)\n",
    "\n",
    "#     names = names[['Stock','Date','PCT_Change_Close']]\n",
    "#     matrix = pd.pivot_table(names,index='Stock',columns='Date',values='PCT_Change_Close')\n",
    "\n",
    "# pd.options.display.float_format = '${:,.2f}'.format\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.drop(stock.index[-99:],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock</th>\n",
       "      <th>Days 0</th>\n",
       "      <th>Days 1</th>\n",
       "      <th>Days 2</th>\n",
       "      <th>Days 3</th>\n",
       "      <th>Days 4</th>\n",
       "      <th>Days 5</th>\n",
       "      <th>Days 6</th>\n",
       "      <th>Days 7</th>\n",
       "      <th>Days 8</th>\n",
       "      <th>...</th>\n",
       "      <th>Days 90</th>\n",
       "      <th>Days 91</th>\n",
       "      <th>Days 92</th>\n",
       "      <th>Days 93</th>\n",
       "      <th>Days 94</th>\n",
       "      <th>Days 95</th>\n",
       "      <th>Days 96</th>\n",
       "      <th>Days 97</th>\n",
       "      <th>Days 98</th>\n",
       "      <th>Days 99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACES</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363343</td>\n",
       "      <td>0.764280</td>\n",
       "      <td>0.758483</td>\n",
       "      <td>-0.079239</td>\n",
       "      <td>0.277557</td>\n",
       "      <td>-0.079083</td>\n",
       "      <td>-0.435299</td>\n",
       "      <td>-0.278219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.990917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.185609</td>\n",
       "      <td>-1.075714</td>\n",
       "      <td>-1.212882</td>\n",
       "      <td>0.592718</td>\n",
       "      <td>2.230640</td>\n",
       "      <td>-0.782215</td>\n",
       "      <td>-2.074689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACES</td>\n",
       "      <td>0.363343</td>\n",
       "      <td>0.764280</td>\n",
       "      <td>0.758483</td>\n",
       "      <td>-0.079239</td>\n",
       "      <td>0.277557</td>\n",
       "      <td>-0.079083</td>\n",
       "      <td>-0.435299</td>\n",
       "      <td>-0.278219</td>\n",
       "      <td>-0.438422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.185609</td>\n",
       "      <td>-1.075714</td>\n",
       "      <td>-1.212882</td>\n",
       "      <td>0.592718</td>\n",
       "      <td>2.230640</td>\n",
       "      <td>-0.782215</td>\n",
       "      <td>-2.074689</td>\n",
       "      <td>0.847458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACES</td>\n",
       "      <td>0.764280</td>\n",
       "      <td>0.758483</td>\n",
       "      <td>-0.079239</td>\n",
       "      <td>0.277557</td>\n",
       "      <td>-0.079083</td>\n",
       "      <td>-0.435299</td>\n",
       "      <td>-0.278219</td>\n",
       "      <td>-0.438422</td>\n",
       "      <td>-0.440352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.185609</td>\n",
       "      <td>-1.075714</td>\n",
       "      <td>-1.212882</td>\n",
       "      <td>0.592718</td>\n",
       "      <td>2.230640</td>\n",
       "      <td>-0.782215</td>\n",
       "      <td>-2.074689</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.546218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACES</td>\n",
       "      <td>0.758483</td>\n",
       "      <td>-0.079239</td>\n",
       "      <td>0.277557</td>\n",
       "      <td>-0.079083</td>\n",
       "      <td>-0.435299</td>\n",
       "      <td>-0.278219</td>\n",
       "      <td>-0.438422</td>\n",
       "      <td>-0.440352</td>\n",
       "      <td>0.201045</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.185609</td>\n",
       "      <td>-1.075714</td>\n",
       "      <td>-1.212882</td>\n",
       "      <td>0.592718</td>\n",
       "      <td>2.230640</td>\n",
       "      <td>-0.782215</td>\n",
       "      <td>-2.074689</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.546218</td>\n",
       "      <td>1.504388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACES</td>\n",
       "      <td>-0.079239</td>\n",
       "      <td>0.277557</td>\n",
       "      <td>-0.079083</td>\n",
       "      <td>-0.435299</td>\n",
       "      <td>-0.278219</td>\n",
       "      <td>-0.438422</td>\n",
       "      <td>-0.440352</td>\n",
       "      <td>0.201045</td>\n",
       "      <td>0.200642</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.075714</td>\n",
       "      <td>-1.212882</td>\n",
       "      <td>0.592718</td>\n",
       "      <td>2.230640</td>\n",
       "      <td>-0.782215</td>\n",
       "      <td>-2.074689</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.546218</td>\n",
       "      <td>1.504388</td>\n",
       "      <td>1.070399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>ACES</td>\n",
       "      <td>1.400467</td>\n",
       "      <td>0.361723</td>\n",
       "      <td>-0.131062</td>\n",
       "      <td>-0.229659</td>\n",
       "      <td>-0.690562</td>\n",
       "      <td>2.019868</td>\n",
       "      <td>-0.681597</td>\n",
       "      <td>0.424837</td>\n",
       "      <td>0.520664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.997147</td>\n",
       "      <td>0.671329</td>\n",
       "      <td>0.194498</td>\n",
       "      <td>0.831947</td>\n",
       "      <td>0.660066</td>\n",
       "      <td>0.601093</td>\n",
       "      <td>-0.543183</td>\n",
       "      <td>0.245767</td>\n",
       "      <td>-0.490330</td>\n",
       "      <td>-1.861484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>ACES</td>\n",
       "      <td>0.361723</td>\n",
       "      <td>-0.131062</td>\n",
       "      <td>-0.229659</td>\n",
       "      <td>-0.690562</td>\n",
       "      <td>2.019868</td>\n",
       "      <td>-0.681597</td>\n",
       "      <td>0.424837</td>\n",
       "      <td>0.520664</td>\n",
       "      <td>1.262545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671329</td>\n",
       "      <td>0.194498</td>\n",
       "      <td>0.831947</td>\n",
       "      <td>0.660066</td>\n",
       "      <td>0.601093</td>\n",
       "      <td>-0.543183</td>\n",
       "      <td>0.245767</td>\n",
       "      <td>-0.490330</td>\n",
       "      <td>-1.861484</td>\n",
       "      <td>2.175732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>ACES</td>\n",
       "      <td>-0.131062</td>\n",
       "      <td>-0.229659</td>\n",
       "      <td>-0.690562</td>\n",
       "      <td>2.019868</td>\n",
       "      <td>-0.681597</td>\n",
       "      <td>0.424837</td>\n",
       "      <td>0.520664</td>\n",
       "      <td>1.262545</td>\n",
       "      <td>0.159847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194498</td>\n",
       "      <td>0.831947</td>\n",
       "      <td>0.660066</td>\n",
       "      <td>0.601093</td>\n",
       "      <td>-0.543183</td>\n",
       "      <td>0.245767</td>\n",
       "      <td>-0.490330</td>\n",
       "      <td>-1.861484</td>\n",
       "      <td>2.175732</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>ACES</td>\n",
       "      <td>-0.229659</td>\n",
       "      <td>-0.690562</td>\n",
       "      <td>2.019868</td>\n",
       "      <td>-0.681597</td>\n",
       "      <td>0.424837</td>\n",
       "      <td>0.520664</td>\n",
       "      <td>1.262545</td>\n",
       "      <td>0.159847</td>\n",
       "      <td>1.021385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831947</td>\n",
       "      <td>0.660066</td>\n",
       "      <td>0.601093</td>\n",
       "      <td>-0.543183</td>\n",
       "      <td>0.245767</td>\n",
       "      <td>-0.490330</td>\n",
       "      <td>-1.861484</td>\n",
       "      <td>2.175732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>ACES</td>\n",
       "      <td>-0.690562</td>\n",
       "      <td>2.019868</td>\n",
       "      <td>-0.681597</td>\n",
       "      <td>0.424837</td>\n",
       "      <td>0.520664</td>\n",
       "      <td>1.262545</td>\n",
       "      <td>0.159847</td>\n",
       "      <td>1.021385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660066</td>\n",
       "      <td>0.601093</td>\n",
       "      <td>-0.543183</td>\n",
       "      <td>0.245767</td>\n",
       "      <td>-0.490330</td>\n",
       "      <td>-1.861484</td>\n",
       "      <td>2.175732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764401</td>\n",
       "      <td>-1.381739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stock    Days 0    Days 1    Days 2    Days 3    Days 4    Days 5  \\\n",
       "0    ACES  0.000000  0.363343  0.764280  0.758483 -0.079239  0.277557   \n",
       "1    ACES  0.363343  0.764280  0.758483 -0.079239  0.277557 -0.079083   \n",
       "2    ACES  0.764280  0.758483 -0.079239  0.277557 -0.079083 -0.435299   \n",
       "3    ACES  0.758483 -0.079239  0.277557 -0.079083 -0.435299 -0.278219   \n",
       "4    ACES -0.079239  0.277557 -0.079083 -0.435299 -0.278219 -0.438422   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "295  ACES  1.400467  0.361723 -0.131062 -0.229659 -0.690562  2.019868   \n",
       "296  ACES  0.361723 -0.131062 -0.229659 -0.690562  2.019868 -0.681597   \n",
       "297  ACES -0.131062 -0.229659 -0.690562  2.019868 -0.681597  0.424837   \n",
       "298  ACES -0.229659 -0.690562  2.019868 -0.681597  0.424837  0.520664   \n",
       "299  ACES -0.690562  2.019868 -0.681597  0.424837  0.520664  1.262545   \n",
       "\n",
       "       Days 6    Days 7    Days 8  ...   Days 90   Days 91   Days 92  \\\n",
       "0   -0.079083 -0.435299 -0.278219  ...  0.000000  0.990917  0.000000   \n",
       "1   -0.435299 -0.278219 -0.438422  ...  0.990917  0.000000 -1.185609   \n",
       "2   -0.278219 -0.438422 -0.440352  ...  0.000000 -1.185609 -1.075714   \n",
       "3   -0.438422 -0.440352  0.201045  ... -1.185609 -1.075714 -1.212882   \n",
       "4   -0.440352  0.201045  0.200642  ... -1.075714 -1.212882  0.592718   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295 -0.681597  0.424837  0.520664  ...  1.997147  0.671329  0.194498   \n",
       "296  0.424837  0.520664  1.262545  ...  0.671329  0.194498  0.831947   \n",
       "297  0.520664  1.262545  0.159847  ...  0.194498  0.831947  0.660066   \n",
       "298  1.262545  0.159847  1.021385  ...  0.831947  0.660066  0.601093   \n",
       "299  0.159847  1.021385  0.000000  ...  0.660066  0.601093 -0.543183   \n",
       "\n",
       "      Days 93   Days 94   Days 95   Days 96   Days 97   Days 98   Days 99  \n",
       "0   -1.185609 -1.075714 -1.212882  0.592718  2.230640 -0.782215 -2.074689  \n",
       "1   -1.075714 -1.212882  0.592718  2.230640 -0.782215 -2.074689  0.847458  \n",
       "2   -1.212882  0.592718  2.230640 -0.782215 -2.074689  0.847458  0.546218  \n",
       "3    0.592718  2.230640 -0.782215 -2.074689  0.847458  0.546218  1.504388  \n",
       "4    2.230640 -0.782215 -2.074689  0.847458  0.546218  1.504388  1.070399  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "295  0.831947  0.660066  0.601093 -0.543183  0.245767 -0.490330 -1.861484  \n",
       "296  0.660066  0.601093 -0.543183  0.245767 -0.490330 -1.861484  2.175732  \n",
       "297  0.601093 -0.543183  0.245767 -0.490330 -1.861484  2.175732  0.000000  \n",
       "298 -0.543183  0.245767 -0.490330 -1.861484  2.175732  0.000000  0.764401  \n",
       "299  0.245767 -0.490330 -1.861484  2.175732  0.000000  0.764401 -1.381739  \n",
       "\n",
       "[300 rows x 101 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.concat(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas_profiling as pp\n",
    "# pp.ProfileReport(list_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciding on Features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X = np.array(stock.loc[:,'Days 1':])\n",
    "y = np.array(stock['Days 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n",
    "                       do_probabilities = False):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=2\n",
    "    )\n",
    "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
    "\n",
    "    if do_probabilities:\n",
    "        pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "        pred = fitted_model.predict(X_test_data)\n",
    "\n",
    "    return fitted_model, pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PARAMETERS={\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    " 'objective':'reg:squarederror',\n",
    " 'eval_metric':'rmse'}\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 700, 1000],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [15,20,25],\n",
    "    'reg_alpha': [1.1, 1.2, 1.3],\n",
    "    'reg_lambda': [1.1, 1.2, 1.3],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With XGBoost Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ creating a custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def example_1(objective,eval_metric,num_boost_round,X,y):\n",
    "#     \"\"\"\n",
    "#     Simple data\n",
    "#     \"\"\"\n",
    "\n",
    "#     X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "#     parameters = PARAMETERS.copy()\n",
    "#     parameters['objective'] = objective\n",
    "#     parameters['eval_metric'] = eval_metric\n",
    "    \n",
    "    \n",
    "#     data_train = xgb.DMatrix(X_train, y_train)\n",
    "#     data_test = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "#     bst = xgb.train(params=parameters,\n",
    "#                     dtrain=data_train,\n",
    "#                     num_boost_round=num_boost_round,\n",
    "#                     evals=[data_test,\"Test\"],\n",
    "#                     early_stopping_rounds=10)\n",
    "\n",
    "#     cv_results = xgb.cv(\n",
    "#         parameters,\n",
    "#         data_train,\n",
    "#         num_boost_round=num_boost_round,\n",
    "#         seed=42,\n",
    "#         nfold=5,\n",
    "#         early_stopping_rounds=10\n",
    "#     )\n",
    "#     print(\"cv results{}\".format(cv_results))\n",
    "#     print(f\"best MAE score with cv :{cv_results['test-mae-mean'].min()}\")\n",
    "#     print()\n",
    "\n",
    "#     gridsearch_params = [\n",
    "#         (max_depth,min_child_weight)\n",
    "#         for max_depth in range(9,13)\n",
    "#         for min_child_weight in range(5,8)\n",
    "#     ]\n",
    "\n",
    "#     min_mae = float(\"Inf\")\n",
    "#     best_params = None\n",
    "\n",
    "#     for max_depth,min_child_weight in gridsearch_params:\n",
    "#         print(f\"CV with max_depth={max_depth}, min_child_weight={min_child_weight}\")\n",
    "\n",
    "#         parameters['max_depth'] = max_depth\n",
    "#         parameters['min_child_weight'] = min_child_weight\n",
    "\n",
    "#         cv_results = xgb.cv(\n",
    "#             parameters,\n",
    "#             data_train,\n",
    "#             num_boost_round=num_boost_round,\n",
    "#             seed=42,\n",
    "#             nfold=5,\n",
    "#             metrics={'mae'}\n",
    "#             early_stopping_round=10,\n",
    "#         )\n",
    "\n",
    "#         mean_mae = cv_results['test-mae-mean'].min()\n",
    "#         boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "#         print(f\"\\tMAE {mean_mae} for {boost_rounds}\")\n",
    "\n",
    "#         if mean_mae < min_mae:\n",
    "#             min_mae = mean_mae\n",
    "#             best_params = (max_depth,min_child_weight)\n",
    "\n",
    "#     print(f\"Best params: {best_params[0]}, {best_params[1]}, MAE: {min_mae}\")\n",
    "\n",
    "\n",
    "\n",
    "#     dump = bst.get_dump(with_stats=True)\n",
    "#     # for tree in dump:\n",
    "#     #     print(tree)\n",
    "\n",
    "#     pred = bst.predict(data_test)\n",
    "#     pred = pd.DataFrame(pred)\n",
    "#     pred['y_test'] = y_test\n",
    "#     pred['diff'] = pred['y_test'] - pred[0]\n",
    "#     pred['exp'] = (pred.y_test - pred[0])**2\n",
    "#     avg_pred = pred.exp.mean()\n",
    "#     print(pred)\n",
    "#     print(avg_pred)\n",
    "   \n",
    "    \n",
    "\n",
    "#     fig=plt.figure()\n",
    "#     ax=fig.add_axes([0,0,1,1])\n",
    "#     #ax.scatter(pred[0], color='r')\n",
    "#     ax.scatter(pred[0] ,pred['y_test'], color='b')\n",
    "#     ax.set_xlabel('preds')\n",
    "#     ax.set_ylabel('y_test')\n",
    "#     ax.set_title('scatter plot')\n",
    "#     plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = xgb.DMatrix(X_train, y_train)\n",
    "data_test = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ transpose into xgb.booster.Dmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:1.21211\n",
      "Will train until Test-rmse hasn't improved in 10 rounds.\n",
      "[1]\tTest-rmse:1.27276\n",
      "[2]\tTest-rmse:1.23926\n",
      "[3]\tTest-rmse:1.26033\n",
      "[4]\tTest-rmse:1.28421\n",
      "[5]\tTest-rmse:1.2903\n",
      "[6]\tTest-rmse:1.30445\n",
      "[7]\tTest-rmse:1.316\n",
      "[8]\tTest-rmse:1.33074\n",
      "[9]\tTest-rmse:1.33133\n",
      "[10]\tTest-rmse:1.33102\n",
      "Stopping. Best iteration:\n",
      "[0]\tTest-rmse:1.21211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(params=PARAMETERS,\n",
    "                dtrain=data_train,\n",
    "                num_boost_round=999,\n",
    "                evals=[(data_test,\"Test\")],\n",
    "                early_stopping_rounds=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ set maximum num_boost_round node iterations, but set early_stopping_rounds at 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:[f1<1.98111129] yes=1,no=2,missing=1,gain=13.4686394,cover=239\n",
      "\t1:[f0<1.7892642] yes=3,no=4,missing=3,gain=10.1896057,cover=228\n",
      "\t\t3:[f20<-0.688007712] yes=7,no=8,missing=7,gain=9.15513611,cover=214\n",
      "\t\t\t7:[f83<-1.11828804] yes=15,no=16,missing=15,gain=7.32988739,cover=38\n",
      "\t\t\t\t15:[f10<-0.101272874] yes=23,no=24,missing=23,gain=1.93261743,cover=5\n",
      "\t\t\t\t\t23:leaf=0.264907956,cover=2\n",
      "\t\t\t\t\t24:[f0<-0.0414804071] yes=33,no=34,missing=33,gain=0.107294559,cover=3\n",
      "\t\t\t\t\t\t33:leaf=-0.109575495,cover=1\n",
      "\t\t\t\t\t\t34:leaf=-0.00727024116,cover=2\n",
      "\t\t\t\t16:[f54<0.0159438774] yes=25,no=26,missing=25,gain=5.77767181,cover=33\n",
      "\t\t\t\t\t25:[f62<0.282988518] yes=35,no=36,missing=35,gain=1.4975431,cover=16\n",
      "\t\t\t\t\t\t35:leaf=-0.0389590077,cover=8\n",
      "\t\t\t\t\t\t36:leaf=-0.223344758,cover=8\n",
      "\t\t\t\t\t26:[f91<-0.13042061] yes=37,no=38,missing=37,gain=3.29996872,cover=17\n",
      "\t\t\t\t\t\t37:leaf=-0.152886316,cover=5\n",
      "\t\t\t\t\t\t38:leaf=-0.483484894,cover=12\n",
      "\t\t\t8:[f1<0.346495092] yes=17,no=18,missing=17,gain=9.96610069,cover=176\n",
      "\t\t\t\t17:[f39<1.26662934] yes=27,no=28,missing=27,gain=12.3153667,cover=118\n",
      "\t\t\t\t\t27:[f31<0.369427621] yes=39,no=40,missing=39,gain=7.86611557,cover=106\n",
      "\t\t\t\t\t\t39:leaf=-0.217441037,cover=64\n",
      "\t\t\t\t\t\t40:leaf=-0.0493955351,cover=42\n",
      "\t\t\t\t\t28:[f2<-0.214468241] yes=41,no=42,missing=41,gain=2.31694365,cover=12\n",
      "\t\t\t\t\t\t41:leaf=-0.000799824367,cover=5\n",
      "\t\t\t\t\t\t42:leaf=0.259368598,cover=7\n",
      "\t\t\t\t18:[f5<0.0334336348] yes=29,no=30,missing=29,gain=7.5206852,cover=58\n",
      "\t\t\t\t\t29:[f80<-0.111726731] yes=43,no=44,missing=43,gain=6.59791565,cover=26\n",
      "\t\t\t\t\t\t43:leaf=0.342503697,cover=9\n",
      "\t\t\t\t\t\t44:leaf=0.0331512839,cover=17\n",
      "\t\t\t\t\t30:[f14<0.702982306] yes=45,no=46,missing=45,gain=4.94330168,cover=32\n",
      "\t\t\t\t\t\t45:leaf=-0.110510565,cover=28\n",
      "\t\t\t\t\t\t46:leaf=0.213948056,cover=4\n",
      "\t\t4:[f93<0.143893003] yes=9,no=10,missing=9,gain=9.04255676,cover=14\n",
      "\t\t\t9:[f17<0.422489524] yes=19,no=20,missing=19,gain=0.919403911,cover=8\n",
      "\t\t\t\t19:[f1<-0.0992457345] yes=31,no=32,missing=31,gain=0.116720073,cover=4\n",
      "\t\t\t\t\t31:leaf=0.0326214395,cover=2\n",
      "\t\t\t\t\t32:leaf=-0.0514879785,cover=2\n",
      "\t\t\t\t20:leaf=-0.207302526,cover=4\n",
      "\t\t\t10:[f19<-1.20673454] yes=21,no=22,missing=21,gain=3.29301453,cover=6\n",
      "\t\t\t\t21:leaf=-0.172805294,cover=2\n",
      "\t\t\t\t22:leaf=-0.747894466,cover=4\n",
      "\t2:[f90<0.605895162] yes=5,no=6,missing=5,gain=3.95590019,cover=11\n",
      "\t\t5:[f10<-0.975132465] yes=11,no=12,missing=11,gain=0.233081818,cover=7\n",
      "\t\t\t11:leaf=-0.245010912,cover=2\n",
      "\t\t\t12:leaf=-0.639573812,cover=5\n",
      "\t\t6:[f1<2.70480204] yes=13,no=14,missing=13,gain=0.159048915,cover=4\n",
      "\t\t\t13:leaf=-0.180731833,cover=3\n",
      "\t\t\t14:leaf=-0.0213806983,cover=1\n",
      "\n",
      "0:[f88<0.420548558] yes=1,no=2,missing=1,gain=8.9139595,cover=239\n",
      "\t1:[f25<0.590260565] yes=3,no=4,missing=3,gain=8.71757889,cover=146\n",
      "\t\t3:[f51<0.0752746388] yes=7,no=8,missing=7,gain=6.39033508,cover=104\n",
      "\t\t\t7:[f20<-1.5839361] yes=15,no=16,missing=15,gain=5.4235363,cover=50\n",
      "\t\t\t\t15:[f4<-0.247406721] yes=31,no=32,missing=31,gain=1.4700613,cover=7\n",
      "\t\t\t\t\t31:leaf=-0.0292757936,cover=1\n",
      "\t\t\t\t\t32:leaf=-0.449915022,cover=6\n",
      "\t\t\t\t16:[f43<-0.296541393] yes=33,no=34,missing=33,gain=3.62835789,cover=43\n",
      "\t\t\t\t\t33:[f88<-0.316658705] yes=55,no=56,missing=55,gain=0.850473583,cover=9\n",
      "\t\t\t\t\t\t55:leaf=-0.0395642146,cover=5\n",
      "\t\t\t\t\t\t56:leaf=0.129634231,cover=4\n",
      "\t\t\t\t\t34:[f7<0.686943054] yes=57,no=58,missing=57,gain=2.66283989,cover=34\n",
      "\t\t\t\t\t\t57:leaf=-0.1292568,cover=30\n",
      "\t\t\t\t\t\t58:leaf=-0.378408104,cover=4\n",
      "\t\t\t8:[f19<-0.231913507] yes=17,no=18,missing=17,gain=5.26690245,cover=54\n",
      "\t\t\t\t17:[f23<1.12343264] yes=35,no=36,missing=35,gain=3.02181911,cover=15\n",
      "\t\t\t\t\t35:[f5<-1.32785034] yes=59,no=60,missing=59,gain=1.50115013,cover=12\n",
      "\t\t\t\t\t\t59:leaf=-0.0346584953,cover=2\n",
      "\t\t\t\t\t\t60:leaf=0.232439056,cover=10\n",
      "\t\t\t\t\t36:[f1<-0.482437551] yes=61,no=62,missing=61,gain=0.0537666082,cover=3\n",
      "\t\t\t\t\t\t61:leaf=-0.139833391,cover=2\n",
      "\t\t\t\t\t\t62:leaf=-0.0249013305,cover=1\n",
      "\t\t\t\t18:[f57<0.0740713179] yes=37,no=38,missing=37,gain=3.47243261,cover=39\n",
      "\t\t\t\t\t37:[f78<-0.646181941] yes=63,no=64,missing=63,gain=2.74381685,cover=22\n",
      "\t\t\t\t\t\t63:leaf=0.000712118694,cover=7\n",
      "\t\t\t\t\t\t64:leaf=-0.224378824,cover=15\n",
      "\t\t\t\t\t38:[f27<1.18835497] yes=65,no=66,missing=65,gain=2.24312067,cover=17\n",
      "\t\t\t\t\t\t65:leaf=-0.0494317077,cover=12\n",
      "\t\t\t\t\t\t66:leaf=0.172572836,cover=5\n",
      "\t\t4:[f16<0.590260565] yes=9,no=10,missing=9,gain=9.08406639,cover=42\n",
      "\t\t\t9:[f30<0.471031904] yes=19,no=20,missing=19,gain=5.35234547,cover=32\n",
      "\t\t\t\t19:[f18<1.62815905] yes=39,no=40,missing=39,gain=2.28390932,cover=23\n",
      "\t\t\t\t\t39:[f5<0.664440155] yes=67,no=68,missing=67,gain=0.884816885,cover=21\n",
      "\t\t\t\t\t\t67:leaf=-0.144194424,cover=17\n",
      "\t\t\t\t\t\t68:leaf=0.00952419173,cover=4\n",
      "\t\t\t\t\t40:[f0<-0.582377017] yes=69,no=70,missing=69,gain=0.075676024,cover=2\n",
      "\t\t\t\t\t\t69:leaf=0.042332001,cover=1\n",
      "\t\t\t\t\t\t70:leaf=0.209532931,cover=1\n",
      "\t\t\t\t20:[f6<0.0484599546] yes=41,no=42,missing=41,gain=1.22003651,cover=9\n",
      "\t\t\t\t\t41:leaf=-0.429444641,cover=6\n",
      "\t\t\t\t\t42:leaf=-0.133049592,cover=3\n",
      "\t\t\t10:[f63<0.0371195264] yes=21,no=22,missing=21,gain=3.06090736,cover=10\n",
      "\t\t\t\t21:leaf=-0.212995335,cover=4\n",
      "\t\t\t\t22:leaf=-0.62749666,cover=6\n",
      "\t2:[f59<0.787558258] yes=5,no=6,missing=5,gain=11.5104361,cover=93\n",
      "\t\t5:[f45<0.392285436] yes=11,no=12,missing=11,gain=8.61244297,cover=79\n",
      "\t\t\t11:[f19<1.0555315] yes=23,no=24,missing=23,gain=10.0233517,cover=46\n",
      "\t\t\t\t23:[f4<0.927216768] yes=43,no=44,missing=43,gain=4.40714025,cover=37\n",
      "\t\t\t\t\t43:[f6<-0.881792784] yes=71,no=72,missing=71,gain=4.364676,cover=30\n",
      "\t\t\t\t\t\t71:leaf=-0.172415704,cover=5\n",
      "\t\t\t\t\t\t72:leaf=0.112755984,cover=25\n",
      "\t\t\t\t\t44:[f7<0.61987865] yes=73,no=74,missing=73,gain=1.04748821,cover=7\n",
      "\t\t\t\t\t\t73:leaf=-0.299857765,cover=3\n",
      "\t\t\t\t\t\t74:leaf=-0.0618477017,cover=4\n",
      "\t\t\t\t24:[f5<0.177471444] yes=45,no=46,missing=45,gain=0.616752625,cover=9\n",
      "\t\t\t\t\t45:leaf=-0.387460887,cover=6\n",
      "\t\t\t\t\t46:leaf=-0.14202784,cover=3\n",
      "\t\t\t12:[f72<0.204819918] yes=25,no=26,missing=25,gain=5.09658241,cover=33\n",
      "\t\t\t\t25:[f60<0.212392926] yes=47,no=48,missing=47,gain=0.161783218,cover=10\n",
      "\t\t\t\t\t47:leaf=0.171817109,cover=4\n",
      "\t\t\t\t\t48:leaf=0.356958538,cover=6\n",
      "\t\t\t\t26:[f79<-0.0350397602] yes=49,no=50,missing=49,gain=2.53678203,cover=23\n",
      "\t\t\t\t\t49:[f33<-0.114594795] yes=75,no=76,missing=75,gain=0.410848379,cover=8\n",
      "\t\t\t\t\t\t75:leaf=0.243167773,cover=4\n",
      "\t\t\t\t\t\t76:leaf=0.0805759504,cover=4\n",
      "\t\t\t\t\t50:[f19<-0.146109432] yes=77,no=78,missing=77,gain=1.24048829,cover=15\n",
      "\t\t\t\t\t\t77:leaf=0.0407168865,cover=10\n",
      "\t\t\t\t\t\t78:leaf=-0.129159778,cover=5\n",
      "\t\t6:[f23<0.651668906] yes=13,no=14,missing=13,gain=4.78637314,cover=14\n",
      "\t\t\t13:[f23<0.367845535] yes=27,no=28,missing=27,gain=0.400389433,cover=10\n",
      "\t\t\t\t27:[f8<-0.497803032] yes=51,no=52,missing=51,gain=0.0263459682,cover=8\n",
      "\t\t\t\t\t51:leaf=-0.065235123,cover=2\n",
      "\t\t\t\t\t52:leaf=-0.172872275,cover=6\n",
      "\t\t\t\t28:[f0<1.213184] yes=53,no=54,missing=53,gain=0.0425777957,cover=2\n",
      "\t\t\t\t\t53:leaf=0.0271701701,cover=1\n",
      "\t\t\t\t\t54:leaf=-0.0348933823,cover=1\n",
      "\t\t\t14:[f0<-0.579354882] yes=29,no=30,missing=29,gain=1.02614021,cover=4\n",
      "\t\t\t\t29:leaf=-0.103695624,cover=1\n",
      "\t\t\t\t30:leaf=-0.584648073,cover=3\n",
      "\n",
      "0:[f9<0.425728887] yes=1,no=2,missing=1,gain=5.27352333,cover=239\n",
      "\t1:[f60<0.276812315] yes=3,no=4,missing=3,gain=5.5741291,cover=155\n",
      "\t\t3:[f51<0.154913902] yes=7,no=8,missing=7,gain=4.31577301,cover=95\n",
      "\t\t\t7:[f88<0.444976449] yes=15,no=16,missing=15,gain=3.14819241,cover=42\n",
      "\t\t\t\t15:[f30<0.907253742] yes=27,no=28,missing=27,gain=1.99010563,cover=28\n",
      "\t\t\t\t\t27:[f54<0.56666708] yes=49,no=50,missing=49,gain=1.44729519,cover=23\n",
      "\t\t\t\t\t\t49:leaf=-0.0653148368,cover=10\n",
      "\t\t\t\t\t\t50:leaf=-0.223945454,cover=13\n",
      "\t\t\t\t\t28:leaf=-0.37562108,cover=5\n",
      "\t\t\t\t16:[f25<-0.0207210947] yes=29,no=30,missing=29,gain=1.45214319,cover=14\n",
      "\t\t\t\t\t29:[f6<0.338465989] yes=51,no=52,missing=51,gain=0.43671906,cover=7\n",
      "\t\t\t\t\t\t51:leaf=0.113261633,cover=4\n",
      "\t\t\t\t\t\t52:leaf=-0.0247659236,cover=3\n",
      "\t\t\t\t\t30:leaf=-0.123122521,cover=7\n",
      "\t\t\t8:[f40<0.329208642] yes=17,no=18,missing=17,gain=2.18902111,cover=53\n",
      "\t\t\t\t17:[f15<0.426964909] yes=31,no=32,missing=31,gain=1.18245065,cover=33\n",
      "\t\t\t\t\t31:[f68<-0.0379617065] yes=53,no=54,missing=53,gain=1.03038645,cover=20\n",
      "\t\t\t\t\t\t53:leaf=-0.0192870367,cover=7\n",
      "\t\t\t\t\t\t54:leaf=-0.163332224,cover=13\n",
      "\t\t\t\t\t32:[f91<-0.57313329] yes=55,no=56,missing=55,gain=0.407738149,cover=13\n",
      "\t\t\t\t\t\t55:leaf=0.0596167147,cover=5\n",
      "\t\t\t\t\t\t56:leaf=-0.0413472913,cover=8\n",
      "\t\t\t\t18:[f26<-0.985358238] yes=33,no=34,missing=33,gain=2.41717339,cover=20\n",
      "\t\t\t\t\t33:[f1<0.100189313] yes=57,no=58,missing=57,gain=0.144718647,cover=5\n",
      "\t\t\t\t\t\t57:leaf=-0.0301436521,cover=2\n",
      "\t\t\t\t\t\t58:leaf=-0.149093896,cover=3\n",
      "\t\t\t\t\t34:[f56<0.382810444] yes=59,no=60,missing=59,gain=0.94140172,cover=15\n",
      "\t\t\t\t\t\t59:leaf=0.159154207,cover=10\n",
      "\t\t\t\t\t\t60:leaf=0.00179586303,cover=5\n",
      "\t\t4:[f11<-0.274047196] yes=9,no=10,missing=9,gain=7.85063171,cover=60\n",
      "\t\t\t9:[f50<-0.835272551] yes=19,no=20,missing=19,gain=3.19730997,cover=18\n",
      "\t\t\t\t19:[f1<-0.515039563] yes=35,no=36,missing=35,gain=0.150601864,cover=6\n",
      "\t\t\t\t\t35:leaf=-0.0729546249,cover=1\n",
      "\t\t\t\t\t36:leaf=-0.313933313,cover=5\n",
      "\t\t\t\t20:[f10<0.0479657464] yes=37,no=38,missing=37,gain=0.86055696,cover=12\n",
      "\t\t\t\t\t37:[f16<-0.857608318] yes=61,no=62,missing=61,gain=0.119035169,cover=6\n",
      "\t\t\t\t\t\t61:leaf=-0.0113374563,cover=2\n",
      "\t\t\t\t\t\t62:leaf=0.0703676194,cover=4\n",
      "\t\t\t\t\t38:leaf=-0.10424573,cover=6\n",
      "\t\t\t10:[f7<1.15595531] yes=21,no=22,missing=21,gain=4.56344604,cover=42\n",
      "\t\t\t\t21:[f53<-0.0541146249] yes=39,no=40,missing=39,gain=3.19354343,cover=34\n",
      "\t\t\t\t\t39:[f63<0.425759703] yes=63,no=64,missing=63,gain=1.69400334,cover=13\n",
      "\t\t\t\t\t\t63:leaf=-0.0433948189,cover=9\n",
      "\t\t\t\t\t\t64:leaf=0.171062022,cover=4\n",
      "\t\t\t\t\t40:[f91<0.471150517] yes=65,no=66,missing=65,gain=2.019907,cover=21\n",
      "\t\t\t\t\t\t65:leaf=0.28344357,cover=14\n",
      "\t\t\t\t\t\t66:leaf=0.0743046403,cover=7\n",
      "\t\t\t\t22:[f21<-0.084940739] yes=41,no=42,missing=41,gain=1.68751109,cover=8\n",
      "\t\t\t\t\t41:[f0<0.712683022] yes=67,no=68,missing=67,gain=0.0188272595,cover=2\n",
      "\t\t\t\t\t\t67:leaf=0.0306409802,cover=1\n",
      "\t\t\t\t\t\t68:leaf=0.134482324,cover=1\n",
      "\t\t\t\t\t42:[f3<-1.61244726] yes=69,no=70,missing=69,gain=0.0816643238,cover=6\n",
      "\t\t\t\t\t\t69:leaf=-0.0364492163,cover=1\n",
      "\t\t\t\t\t\t70:leaf=-0.1809479,cover=5\n",
      "\t2:[f56<1.74516201] yes=5,no=6,missing=5,gain=6.95046997,cover=84\n",
      "\t\t5:[f48<1.38653183] yes=11,no=12,missing=11,gain=5.60361958,cover=80\n",
      "\t\t\t11:[f52<0.264365256] yes=23,no=24,missing=23,gain=5.90073586,cover=74\n",
      "\t\t\t\t23:[f21<0.570245385] yes=43,no=44,missing=43,gain=2.15276885,cover=42\n",
      "\t\t\t\t\t43:[f21<0.041841004] yes=71,no=72,missing=71,gain=2.08847046,cover=28\n",
      "\t\t\t\t\t\t71:leaf=-0.0327130668,cover=17\n",
      "\t\t\t\t\t\t72:leaf=-0.19859229,cover=11\n",
      "\t\t\t\t\t44:[f76<-0.143957734] yes=73,no=74,missing=73,gain=0.893284857,cover=14\n",
      "\t\t\t\t\t\t73:leaf=0.128491491,cover=5\n",
      "\t\t\t\t\t\t74:leaf=-0.0191950817,cover=9\n",
      "\t\t\t\t24:[f87<-0.427903891] yes=45,no=46,missing=45,gain=4.56574821,cover=32\n",
      "\t\t\t\t\t45:[f4<-1.30976081] yes=75,no=76,missing=75,gain=1.61227608,cover=6\n",
      "\t\t\t\t\t\t75:leaf=-0.0456489101,cover=1\n",
      "\t\t\t\t\t\t76:leaf=-0.508612156,cover=5\n",
      "\t\t\t\t\t46:[f29<0.566341877] yes=77,no=78,missing=77,gain=1.8760643,cover=26\n",
      "\t\t\t\t\t\t77:leaf=-0.198741287,cover=21\n",
      "\t\t\t\t\t\t78:leaf=0.00404036278,cover=5\n",
      "\t\t\t12:[f8<-0.159258038] yes=25,no=26,missing=25,gain=1.60449278,cover=6\n",
      "\t\t\t\t25:[f2<-0.0892857164] yes=47,no=48,missing=47,gain=0.0355254151,cover=3\n",
      "\t\t\t\t\t47:leaf=-0.0292119756,cover=2\n",
      "\t\t\t\t\t48:leaf=0.0230946429,cover=1\n",
      "\t\t\t\t26:leaf=0.276562482,cover=3\n",
      "\t\t6:[f0<-1.33531344] yes=13,no=14,missing=13,gain=0.130841255,cover=4\n",
      "\t\t\t13:leaf=-0.138832569,cover=1\n",
      "\t\t\t14:leaf=-0.528475583,cover=3\n",
      "\n",
      "0:[f1<1.8697648] yes=1,no=2,missing=1,gain=3.09281683,cover=239\n",
      "\t1:[f0<1.7892642] yes=3,no=4,missing=3,gain=3.22652626,cover=226\n",
      "\t\t3:[f32<-2.59861517] yes=7,no=8,missing=7,gain=2.74004388,cover=212\n",
      "\t\t\t7:[f1<1.27146447] yes=13,no=14,missing=13,gain=0.814437509,cover=5\n",
      "\t\t\t\t13:leaf=0.21670647,cover=4\n",
      "\t\t\t\t14:leaf=-0.0437613502,cover=1\n",
      "\t\t\t8:[f59<0.805047274] yes=15,no=16,missing=15,gain=2.39034653,cover=207\n",
      "\t\t\t\t15:[f88<0.407051504] yes=23,no=24,missing=23,gain=3.46931744,cover=168\n",
      "\t\t\t\t\t23:[f59<0.122497037] yes=29,no=30,missing=29,gain=2.53946209,cover=96\n",
      "\t\t\t\t\t\t29:leaf=-0.0986306593,cover=60\n",
      "\t\t\t\t\t\t30:leaf=0.00179606013,cover=36\n",
      "\t\t\t\t\t24:[f45<0.392285436] yes=31,no=32,missing=31,gain=2.9035213,cover=72\n",
      "\t\t\t\t\t\t31:leaf=-0.0269538108,cover=41\n",
      "\t\t\t\t\t\t32:leaf=0.0931412056,cover=31\n",
      "\t\t\t\t16:[f12<-0.313942075] yes=25,no=26,missing=25,gain=2.22863293,cover=39\n",
      "\t\t\t\t\t25:[f76<-0.214377314] yes=33,no=34,missing=33,gain=1.92218018,cover=12\n",
      "\t\t\t\t\t\t33:leaf=-0.359734118,cover=4\n",
      "\t\t\t\t\t\t34:leaf=-0.101983197,cover=8\n",
      "\t\t\t\t\t26:[f95<0.642635822] yes=35,no=36,missing=35,gain=2.21932864,cover=27\n",
      "\t\t\t\t\t\t35:leaf=-0.00111921714,cover=20\n",
      "\t\t\t\t\t\t36:leaf=-0.188136831,cover=7\n",
      "\t\t4:[f14<0.484732091] yes=9,no=10,missing=9,gain=2.49934721,cover=14\n",
      "\t\t\t9:[f14<-0.128161281] yes=17,no=18,missing=17,gain=0.251218498,cover=9\n",
      "\t\t\t\t17:leaf=-0.108896546,cover=5\n",
      "\t\t\t\t18:[f1<-0.0992457345] yes=27,no=28,missing=27,gain=0.033459682,cover=4\n",
      "\t\t\t\t\t27:leaf=0.0149317812,cover=2\n",
      "\t\t\t\t\t28:leaf=-0.0304054935,cover=2\n",
      "\t\t\t10:[f0<1.81794715] yes=19,no=20,missing=19,gain=0.826986313,cover=5\n",
      "\t\t\t\t19:leaf=-0.0383982919,cover=1\n",
      "\t\t\t\t20:leaf=-0.381514609,cover=4\n",
      "\t2:[f13<0.869121075] yes=5,no=6,missing=5,gain=2.0474534,cover=13\n",
      "\t\t5:[f34<1.03767812] yes=11,no=12,missing=11,gain=0.357070208,cover=11\n",
      "\t\t\t11:leaf=-0.147384122,cover=8\n",
      "\t\t\t12:[f1<2.70480204] yes=21,no=22,missing=21,gain=0.0421562344,cover=3\n",
      "\t\t\t\t21:leaf=-0.0395573676,cover=2\n",
      "\t\t\t\t22:leaf=0.0190300085,cover=1\n",
      "\t\t6:leaf=-0.418670684,cover=2\n",
      "\n",
      "0:[f7<1.19522631] yes=1,no=2,missing=1,gain=2.47929955,cover=239\n",
      "\t1:[f1<1.40886879] yes=3,no=4,missing=3,gain=2.94882727,cover=209\n",
      "\t\t3:[f60<0.169980913] yes=7,no=8,missing=7,gain=2.35075521,cover=187\n",
      "\t\t\t7:[f5<-0.902965307] yes=15,no=16,missing=15,gain=2.23121095,cover=100\n",
      "\t\t\t\t15:[f38<-0.033732146] yes=29,no=30,missing=29,gain=0.896535158,cover=12\n",
      "\t\t\t\t\t29:[f11<0.569127023] yes=47,no=48,missing=47,gain=0.125885248,cover=7\n",
      "\t\t\t\t\t\t47:leaf=-0.105239116,cover=4\n",
      "\t\t\t\t\t\t48:leaf=-0.0193576217,cover=3\n",
      "\t\t\t\t\t30:leaf=-0.250515074,cover=5\n",
      "\t\t\t\t16:[f16<0.183037758] yes=31,no=32,missing=31,gain=1.52358937,cover=88\n",
      "\t\t\t\t\t31:[f7<-0.989869177] yes=49,no=50,missing=49,gain=0.949643016,cover=52\n",
      "\t\t\t\t\t\t49:leaf=0.100029662,cover=7\n",
      "\t\t\t\t\t\t50:leaf=-0.011973341,cover=45\n",
      "\t\t\t\t\t32:[f32<-0.0411353335] yes=51,no=52,missing=51,gain=1.62135482,cover=36\n",
      "\t\t\t\t\t\t51:leaf=-0.135998294,cover=18\n",
      "\t\t\t\t\t\t52:leaf=-0.00976652279,cover=18\n",
      "\t\t\t8:[f27<-0.159313172] yes=17,no=18,missing=17,gain=3.66075754,cover=87\n",
      "\t\t\t\t17:[f90<1.25076771] yes=33,no=34,missing=33,gain=2.08852673,cover=32\n",
      "\t\t\t\t\t33:[f24<1.48194718] yes=53,no=54,missing=53,gain=1.43007421,cover=28\n",
      "\t\t\t\t\t\t53:leaf=0.00120193674,cover=25\n",
      "\t\t\t\t\t\t54:leaf=-0.191947743,cover=3\n",
      "\t\t\t\t\t34:[f1<-0.284820259] yes=55,no=56,missing=55,gain=0.104566574,cover=4\n",
      "\t\t\t\t\t\t55:leaf=-0.294497073,cover=2\n",
      "\t\t\t\t\t\t56:leaf=-0.10078644,cover=2\n",
      "\t\t\t\t18:[f7<0.820241988] yes=35,no=36,missing=35,gain=2.87671185,cover=55\n",
      "\t\t\t\t\t35:[f84<-0.29393363] yes=57,no=58,missing=57,gain=1.66908109,cover=50\n",
      "\t\t\t\t\t\t57:leaf=0.131547093,cover=13\n",
      "\t\t\t\t\t\t58:leaf=0.00963504706,cover=37\n",
      "\t\t\t\t\t36:leaf=0.264803916,cover=5\n",
      "\t\t4:[f89<0.341889739] yes=9,no=10,missing=9,gain=3.01502752,cover=22\n",
      "\t\t\t9:[f15<0.705426574] yes=19,no=20,missing=19,gain=0.595053971,cover=14\n",
      "\t\t\t\t19:[f1<1.61493897] yes=37,no=38,missing=37,gain=0.0639254451,cover=9\n",
      "\t\t\t\t\t37:leaf=-0.00463274727,cover=1\n",
      "\t\t\t\t\t38:leaf=-0.089516595,cover=8\n",
      "\t\t\t\t20:[f1<1.42380583] yes=39,no=40,missing=39,gain=0.0338021144,cover=5\n",
      "\t\t\t\t\t39:leaf=-0.00566217024,cover=1\n",
      "\t\t\t\t\t40:leaf=0.0497295037,cover=4\n",
      "\t\t\t10:[f64<0.425520897] yes=21,no=22,missing=21,gain=1.85850954,cover=8\n",
      "\t\t\t\t21:[f1<2.27873063] yes=41,no=42,missing=41,gain=0.0188132524,cover=4\n",
      "\t\t\t\t\t41:leaf=-0.0975650921,cover=3\n",
      "\t\t\t\t\t42:leaf=-0.0205988735,cover=1\n",
      "\t\t\t\t22:leaf=-0.389747709,cover=4\n",
      "\t2:[f36<-0.175307065] yes=5,no=6,missing=5,gain=2.46210766,cover=30\n",
      "\t\t5:[f64<0.254737139] yes=11,no=12,missing=11,gain=0.651705801,cover=12\n",
      "\t\t\t11:[f40<0.261180192] yes=23,no=24,missing=23,gain=0.134257868,cover=8\n",
      "\t\t\t\t23:[f2<1.36493063] yes=43,no=44,missing=43,gain=0.0167453047,cover=4\n",
      "\t\t\t\t\t43:leaf=-0.0178388562,cover=2\n",
      "\t\t\t\t\t44:leaf=0.0139071681,cover=2\n",
      "\t\t\t\t24:[f0<0.792553663] yes=45,no=46,missing=45,gain=0.0105084181,cover=4\n",
      "\t\t\t\t\t45:leaf=0.0383449607,cover=3\n",
      "\t\t\t\t\t46:leaf=0.100338779,cover=1\n",
      "\t\t\t12:leaf=-0.0971856639,cover=4\n",
      "\t\t6:[f12<-1.25261319] yes=13,no=14,missing=13,gain=1.30977297,cover=18\n",
      "\t\t\t13:[f2<0.330283165] yes=25,no=26,missing=25,gain=0.0113345534,cover=4\n",
      "\t\t\t\t25:leaf=-0.0331711583,cover=3\n",
      "\t\t\t\t26:leaf=0.00129843957,cover=1\n",
      "\t\t\t14:[f25<0.646552265] yes=27,no=28,missing=27,gain=0.514208794,cover=14\n",
      "\t\t\t\t27:leaf=-0.279988855,cover=8\n",
      "\t\t\t\t28:leaf=-0.125200167,cover=6\n",
      "\n",
      "0:[f47<-1.11780441] yes=1,no=2,missing=1,gain=1.7140584,cover=239\n",
      "\t1:[f38<-0.95899117] yes=3,no=4,missing=3,gain=1.48067188,cover=27\n",
      "\t\t3:leaf=-0.24947165,cover=4\n",
      "\t\t4:[f66<0.990606546] yes=7,no=8,missing=7,gain=0.805939555,cover=23\n",
      "\t\t\t7:[f11<0.15463376] yes=13,no=14,missing=13,gain=0.641358733,cover=18\n",
      "\t\t\t\t13:[f84<0.279710442] yes=25,no=26,missing=25,gain=0.10677433,cover=9\n",
      "\t\t\t\t\t25:leaf=-0.178469226,cover=5\n",
      "\t\t\t\t\t26:leaf=-0.0758428723,cover=4\n",
      "\t\t\t\t14:[f1<-0.147275403] yes=27,no=28,missing=27,gain=0.0607520938,cover=9\n",
      "\t\t\t\t\t27:[f0<-0.291036099] yes=41,no=42,missing=41,gain=0.00363647472,cover=3\n",
      "\t\t\t\t\t\t41:leaf=-0.00343455095,cover=2\n",
      "\t\t\t\t\t\t42:leaf=0.0134217301,cover=1\n",
      "\t\t\t\t\t28:[f6<0.704619884] yes=43,no=44,missing=43,gain=0.00287598372,cover=6\n",
      "\t\t\t\t\t\t43:leaf=-0.0492257439,cover=5\n",
      "\t\t\t\t\t\t44:leaf=-0.0119895423,cover=1\n",
      "\t\t\t8:[f0<0.715580583] yes=15,no=16,missing=15,gain=0.0836141407,cover=5\n",
      "\t\t\t\t15:leaf=0.0542096719,cover=4\n",
      "\t\t\t\t16:leaf=-0.0238838382,cover=1\n",
      "\t2:[f78<1.26438403] yes=5,no=6,missing=5,gain=1.64959359,cover=212\n",
      "\t\t5:[f48<1.53725326] yes=9,no=10,missing=9,gain=1.30354989,cover=188\n",
      "\t\t\t9:[f9<0.684623599] yes=17,no=18,missing=17,gain=1.47272778,cover=176\n",
      "\t\t\t\t17:[f15<0.0165398605] yes=29,no=30,missing=29,gain=1.75109911,cover=131\n",
      "\t\t\t\t\t29:[f50<0.375036299] yes=45,no=46,missing=45,gain=1.5736531,cover=59\n",
      "\t\t\t\t\t\t45:leaf=-0.0744847581,cover=38\n",
      "\t\t\t\t\t\t46:leaf=0.0263821762,cover=21\n",
      "\t\t\t\t\t30:[f10<-1.67733347] yes=47,no=48,missing=47,gain=0.952283561,cover=72\n",
      "\t\t\t\t\t\t47:leaf=0.196465746,cover=2\n",
      "\t\t\t\t\t\t48:leaf=0.0229920745,cover=70\n",
      "\t\t\t\t18:[f57<0.363735616] yes=31,no=32,missing=31,gain=1.45255971,cover=45\n",
      "\t\t\t\t\t31:[f98<1.46881723] yes=49,no=50,missing=49,gain=0.991798162,cover=29\n",
      "\t\t\t\t\t\t49:leaf=-0.123657227,cover=25\n",
      "\t\t\t\t\t\t50:leaf=0.0302659161,cover=4\n",
      "\t\t\t\t\t32:[f62<-0.791845679] yes=51,no=52,missing=51,gain=0.391396523,cover=16\n",
      "\t\t\t\t\t\t51:leaf=0.0801633522,cover=4\n",
      "\t\t\t\t\t\t52:leaf=-0.0187166482,cover=12\n",
      "\t\t\t10:[f75<-0.327467322] yes=19,no=20,missing=19,gain=1.64856362,cover=12\n",
      "\t\t\t\t19:leaf=0.241768643,cover=3\n",
      "\t\t\t\t20:[f41<-0.998814225] yes=33,no=34,missing=33,gain=0.248269588,cover=9\n",
      "\t\t\t\t\t33:[f0<-0.233503029] yes=53,no=54,missing=53,gain=0.0220575184,cover=2\n",
      "\t\t\t\t\t\t53:leaf=0.103519559,cover=1\n",
      "\t\t\t\t\t\t54:leaf=0.0196180344,cover=1\n",
      "\t\t\t\t\t34:[f12<0.106065378] yes=55,no=56,missing=55,gain=0.0219511464,cover=7\n",
      "\t\t\t\t\t\t55:leaf=0.000757927482,cover=3\n",
      "\t\t\t\t\t\t56:leaf=-0.0314557739,cover=4\n",
      "\t\t6:[f47<0.0165398605] yes=11,no=12,missing=11,gain=1.88484478,cover=24\n",
      "\t\t\t11:[f0<0.147306398] yes=21,no=22,missing=21,gain=0.0512869954,cover=5\n",
      "\t\t\t\t21:leaf=0.092104733,cover=2\n",
      "\t\t\t\t22:[f2<5.66057861e-05] yes=35,no=36,missing=35,gain=0.000619504601,cover=3\n",
      "\t\t\t\t\t35:leaf=0.0276267026,cover=2\n",
      "\t\t\t\t\t36:leaf=0.00679027149,cover=1\n",
      "\t\t\t12:[f49<-1.00408542] yes=23,no=24,missing=23,gain=1.15637922,cover=19\n",
      "\t\t\t\t23:[f0<1.42380583] yes=37,no=38,missing=37,gain=0.120993249,cover=3\n",
      "\t\t\t\t\t37:[f0<0.476481318] yes=57,no=58,missing=57,gain=0.000500197522,cover=2\n",
      "\t\t\t\t\t\t57:leaf=-0.0198974144,cover=1\n",
      "\t\t\t\t\t\t58:leaf=-0.00436534919,cover=1\n",
      "\t\t\t\t\t38:leaf=0.0819532797,cover=1\n",
      "\t\t\t\t24:[f47<0.543379545] yes=39,no=40,missing=39,gain=0.612683773,cover=16\n",
      "\t\t\t\t\t39:[f4<0.151496321] yes=59,no=60,missing=59,gain=0.175632477,cover=7\n",
      "\t\t\t\t\t\t59:leaf=-0.249488056,cover=6\n",
      "\t\t\t\t\t\t60:leaf=-0.0482727848,cover=1\n",
      "\t\t\t\t\t40:[f3<-0.687215686] yes=61,no=62,missing=61,gain=0.0839892626,cover=9\n",
      "\t\t\t\t\t\t61:leaf=-0.00633426057,cover=1\n",
      "\t\t\t\t\t\t62:leaf=-0.104799367,cover=8\n",
      "\n",
      "0:[f7<1.19522631] yes=1,no=2,missing=1,gain=1.14027512,cover=239\n",
      "\t1:[f1<1.40886879] yes=3,no=4,missing=3,gain=1.29628849,cover=209\n",
      "\t\t3:[f34<-1.5839361] yes=7,no=8,missing=7,gain=1.10150385,cover=187\n",
      "\t\t\t7:[f59<0.365197718] yes=15,no=16,missing=15,gain=0.659468651,cover=10\n",
      "\t\t\t\t15:leaf=0.168321937,cover=4\n",
      "\t\t\t\t16:[f3<-0.702866077] yes=31,no=32,missing=31,gain=0.0632930622,cover=6\n",
      "\t\t\t\t\t31:leaf=-0.0199757703,cover=2\n",
      "\t\t\t\t\t32:leaf=0.0364174135,cover=4\n",
      "\t\t\t8:[f87<0.910071373] yes=17,no=18,missing=17,gain=1.20958638,cover=177\n",
      "\t\t\t\t17:[f0<-0.810570538] yes=33,no=34,missing=33,gain=1.20501506,cover=146\n",
      "\t\t\t\t\t33:[f78<0.168954611] yes=45,no=46,missing=45,gain=1.19011903,cover=25\n",
      "\t\t\t\t\t\t45:leaf=0.0219009593,cover=10\n",
      "\t\t\t\t\t\t46:leaf=-0.108163372,cover=15\n",
      "\t\t\t\t\t34:[f39<-1.61497855] yes=47,no=48,missing=47,gain=0.929097652,cover=121\n",
      "\t\t\t\t\t\t47:leaf=0.140534982,cover=4\n",
      "\t\t\t\t\t\t48:leaf=0.00835330412,cover=117\n",
      "\t\t\t\t18:[f32<0.817655265] yes=35,no=36,missing=35,gain=0.584624171,cover=31\n",
      "\t\t\t\t\t35:[f68<-0.197130769] yes=49,no=50,missing=49,gain=0.436435044,cover=26\n",
      "\t\t\t\t\t\t49:leaf=0.00739804702,cover=10\n",
      "\t\t\t\t\t\t50:leaf=-0.0709065422,cover=16\n",
      "\t\t\t\t\t36:[f0<1.16946375] yes=51,no=52,missing=51,gain=0.414880514,cover=5\n",
      "\t\t\t\t\t\t51:leaf=-0.184353977,cover=4\n",
      "\t\t\t\t\t\t52:leaf=0.0142341908,cover=1\n",
      "\t\t4:[f89<0.341889739] yes=9,no=10,missing=9,gain=1.31311798,cover=22\n",
      "\t\t\t9:[f15<1.03320634] yes=19,no=20,missing=19,gain=0.257834226,cover=14\n",
      "\t\t\t\t19:[f67<-0.19279775] yes=37,no=38,missing=37,gain=0.0731058419,cover=10\n",
      "\t\t\t\t\t37:[f0<0.35203585] yes=53,no=54,missing=53,gain=0.00398039212,cover=3\n",
      "\t\t\t\t\t\t53:leaf=-0.010374343,cover=2\n",
      "\t\t\t\t\t\t54:leaf=0.00723488349,cover=1\n",
      "\t\t\t\t\t38:[f1<2.26332426] yes=55,no=56,missing=55,gain=0.00161212683,cover=7\n",
      "\t\t\t\t\t\t55:leaf=-0.0642303452,cover=6\n",
      "\t\t\t\t\t\t56:leaf=-0.0174421147,cover=1\n",
      "\t\t\t\t20:leaf=0.0373291709,cover=4\n",
      "\t\t\t10:[f64<0.425520897] yes=21,no=22,missing=21,gain=0.788598537,cover=8\n",
      "\t\t\t\t21:leaf=-0.0542465039,cover=4\n",
      "\t\t\t\t22:leaf=-0.251093447,cover=4\n",
      "\t2:[f36<-0.175307065] yes=5,no=6,missing=5,gain=1.01635993,cover=30\n",
      "\t\t5:[f5<0.110440835] yes=11,no=12,missing=11,gain=0.335004538,cover=12\n",
      "\t\t\t11:[f15<0.636134207] yes=23,no=24,missing=23,gain=0.0925301835,cover=8\n",
      "\t\t\t\t23:[f4<0.372827739] yes=39,no=40,missing=39,gain=0.000674962997,cover=3\n",
      "\t\t\t\t\t39:leaf=0.0193289462,cover=1\n",
      "\t\t\t\t\t40:leaf=0.0714799091,cover=2\n",
      "\t\t\t\t24:[f5<-1.13637733] yes=41,no=42,missing=41,gain=0.00772628281,cover=5\n",
      "\t\t\t\t\t41:[f0<-1.54236317] yes=57,no=58,missing=57,gain=0.000185676618,cover=2\n",
      "\t\t\t\t\t\t57:leaf=-0.00273627578,cover=1\n",
      "\t\t\t\t\t\t58:leaf=-0.012366605,cover=1\n",
      "\t\t\t\t\t42:leaf=0.0101076858,cover=3\n",
      "\t\t\t12:[f0<0.737458885] yes=25,no=26,missing=25,gain=0.00340843201,cover=4\n",
      "\t\t\t\t25:leaf=-0.0748972669,cover=3\n",
      "\t\t\t\t26:leaf=-0.0193116646,cover=1\n",
      "\t\t6:[f12<-1.25261319] yes=13,no=14,missing=13,gain=0.453060389,cover=18\n",
      "\t\t\t13:[f2<0.330283165] yes=27,no=28,missing=27,gain=0.00792001933,cover=4\n",
      "\t\t\t\t27:leaf=-0.0279107057,cover=3\n",
      "\t\t\t\t28:leaf=0.000989985536,cover=1\n",
      "\t\t\t14:[f29<-0.0931490436] yes=29,no=30,missing=29,gain=0.39509511,cover=14\n",
      "\t\t\t\t29:leaf=-0.199150428,cover=6\n",
      "\t\t\t\t30:[f0<0.87759304] yes=43,no=44,missing=43,gain=0.00945687294,cover=8\n",
      "\t\t\t\t\t43:leaf=-0.0864953399,cover=7\n",
      "\t\t\t\t\t44:leaf=-0.0211104564,cover=1\n",
      "\n",
      "0:[f60<0.1763836] yes=1,no=2,missing=1,gain=0.962659717,cover=239\n",
      "\t1:[f13<-2.41659331] yes=3,no=4,missing=3,gain=1.00917399,cover=128\n",
      "\t\t3:[f0<-1.16952682] yes=7,no=8,missing=7,gain=0.0346316099,cover=5\n",
      "\t\t\t7:leaf=0.0164232645,cover=1\n",
      "\t\t\t8:leaf=0.0990851671,cover=4\n",
      "\t\t4:[f77<-0.769205093] yes=9,no=10,missing=9,gain=0.978022099,cover=123\n",
      "\t\t\t9:[f7<0.196394265] yes=15,no=16,missing=15,gain=0.378992051,cover=24\n",
      "\t\t\t\t15:[f95<0.293096006] yes=27,no=28,missing=27,gain=0.10647165,cover=14\n",
      "\t\t\t\t\t27:[f20<0.692136288] yes=45,no=46,missing=45,gain=0.00986301899,cover=7\n",
      "\t\t\t\t\t\t45:leaf=-0.0472219288,cover=5\n",
      "\t\t\t\t\t\t46:leaf=-0.0130708097,cover=2\n",
      "\t\t\t\t\t28:[f9<-0.904110909] yes=47,no=48,missing=47,gain=0.0347246416,cover=7\n",
      "\t\t\t\t\t\t47:leaf=-0.018426137,cover=2\n",
      "\t\t\t\t\t\t48:leaf=0.0215847827,cover=5\n",
      "\t\t\t\t16:[f20<-0.0856125206] yes=29,no=30,missing=29,gain=0.314379394,cover=10\n",
      "\t\t\t\t\t29:[f41<-0.0201875567] yes=49,no=50,missing=49,gain=0.0433273986,cover=7\n",
      "\t\t\t\t\t\t49:leaf=0.0335175395,cover=4\n",
      "\t\t\t\t\t\t50:leaf=-0.00959942304,cover=3\n",
      "\t\t\t\t\t30:leaf=0.124439873,cover=3\n",
      "\t\t\t10:[f48<-0.902965307] yes=17,no=18,missing=17,gain=0.689713717,cover=99\n",
      "\t\t\t\t17:[f76<-0.473664075] yes=31,no=32,missing=31,gain=0.345310062,cover=16\n",
      "\t\t\t\t\t31:[f0<0.239631608] yes=51,no=52,missing=51,gain=0.0685521662,cover=5\n",
      "\t\t\t\t\t\t51:leaf=0.0779197291,cover=4\n",
      "\t\t\t\t\t\t52:leaf=-0.00418423722,cover=1\n",
      "\t\t\t\t\t32:[f1<1.40988088] yes=53,no=54,missing=53,gain=0.0761222541,cover=11\n",
      "\t\t\t\t\t\t53:leaf=-0.0125635965,cover=10\n",
      "\t\t\t\t\t\t54:leaf=-0.0787412822,cover=1\n",
      "\t\t\t\t18:[f45<0.832448184] yes=33,no=34,missing=33,gain=0.678640127,cover=83\n",
      "\t\t\t\t\t33:[f26<1.04547524] yes=55,no=56,missing=55,gain=0.592391014,cover=65\n",
      "\t\t\t\t\t\t55:leaf=-0.0935814157,cover=48\n",
      "\t\t\t\t\t\t56:leaf=-0.0265701711,cover=17\n",
      "\t\t\t\t\t34:[f22<-0.0899759084] yes=57,no=58,missing=57,gain=0.369546682,cover=18\n",
      "\t\t\t\t\t\t57:leaf=0.0353008844,cover=8\n",
      "\t\t\t\t\t\t58:leaf=-0.046794612,cover=10\n",
      "\t2:[f27<0.0917412043] yes=5,no=6,missing=5,gain=1.41610074,cover=111\n",
      "\t\t5:[f17<-0.4988693] yes=11,no=12,missing=11,gain=0.737048626,cover=55\n",
      "\t\t\t11:[f91<0.0345523879] yes=19,no=20,missing=19,gain=0.375429034,cover=13\n",
      "\t\t\t\t19:[f1<0.224144921] yes=35,no=36,missing=35,gain=0.0246052053,cover=5\n",
      "\t\t\t\t\t35:[f0<-0.398873776] yes=59,no=60,missing=59,gain=0.0012284182,cover=3\n",
      "\t\t\t\t\t\t59:leaf=-0.00900658127,cover=1\n",
      "\t\t\t\t\t\t60:leaf=-0.0370847583,cover=2\n",
      "\t\t\t\t\t36:[f0<0.262884557] yes=61,no=62,missing=61,gain=0.00068102323,cover=2\n",
      "\t\t\t\t\t\t61:leaf=-0.000224737829,cover=1\n",
      "\t\t\t\t\t\t62:leaf=0.0091468608,cover=1\n",
      "\t\t\t\t20:[f4<-0.950789213] yes=37,no=38,missing=37,gain=0.174215078,cover=8\n",
      "\t\t\t\t\t37:[f1<-0.339858055] yes=63,no=64,missing=63,gain=0.00308404863,cover=3\n",
      "\t\t\t\t\t\t63:leaf=-0.0529986732,cover=2\n",
      "\t\t\t\t\t\t64:leaf=-0.0124841789,cover=1\n",
      "\t\t\t\t\t38:leaf=-0.157497346,cover=5\n",
      "\t\t\t12:[f21<1.03475511] yes=21,no=22,missing=21,gain=0.739331126,cover=42\n",
      "\t\t\t\t21:[f16<0.485083401] yes=39,no=40,missing=39,gain=0.47428906,cover=39\n",
      "\t\t\t\t\t39:[f96<0.191408992] yes=65,no=66,missing=65,gain=0.161610872,cover=24\n",
      "\t\t\t\t\t\t65:leaf=-0.0436534882,cover=13\n",
      "\t\t\t\t\t\t66:leaf=0.00456186477,cover=11\n",
      "\t\t\t\t\t40:[f23<0.20375818] yes=67,no=68,missing=67,gain=0.410109162,cover=15\n",
      "\t\t\t\t\t\t67:leaf=0.0863150433,cover=8\n",
      "\t\t\t\t\t\t68:leaf=-0.00930445269,cover=7\n",
      "\t\t\t\t22:leaf=-0.1316998,cover=3\n",
      "\t\t6:[f48<1.48194718] yes=13,no=14,missing=13,gain=1.10620475,cover=56\n",
      "\t\t\t13:[f81<1.23776531] yes=23,no=24,missing=23,gain=0.914070845,cover=52\n",
      "\t\t\t\t23:[f39<0.564447045] yes=41,no=42,missing=41,gain=0.802396476,cover=48\n",
      "\t\t\t\t\t41:[f39<-0.826168895] yes=69,no=70,missing=69,gain=0.785632133,cover=34\n",
      "\t\t\t\t\t\t69:leaf=0.0585598126,cover=9\n",
      "\t\t\t\t\t\t70:leaf=-0.0405068919,cover=25\n",
      "\t\t\t\t\t42:[f89<0.298827022] yes=71,no=72,missing=71,gain=0.521464527,cover=14\n",
      "\t\t\t\t\t\t71:leaf=0.0213598721,cover=9\n",
      "\t\t\t\t\t\t72:leaf=0.138526171,cover=5\n",
      "\t\t\t\t24:[f2<-0.0983541682] yes=43,no=44,missing=43,gain=0.0967530012,cover=4\n",
      "\t\t\t\t\t43:leaf=0.0281035975,cover=1\n",
      "\t\t\t\t\t44:leaf=0.169605777,cover=3\n",
      "\t\t\t14:[f0<0.248467892] yes=25,no=26,missing=25,gain=0.101652265,cover=4\n",
      "\t\t\t\t25:leaf=0.197917625,cover=3\n",
      "\t\t\t\t26:leaf=0.0377316177,cover=1\n",
      "\n",
      "0:[f0<1.77139902] yes=1,no=2,missing=1,gain=0.598524213,cover=239\n",
      "\t1:[f32<-1.95525229] yes=3,no=4,missing=3,gain=0.681186616,cover=224\n",
      "\t\t3:[f1<1.27146447] yes=7,no=8,missing=7,gain=0.163867652,cover=8\n",
      "\t\t\t7:leaf=0.0961727649,cover=6\n",
      "\t\t\t8:[f0<0.633194566] yes=15,no=16,missing=15,gain=0.000380522222,cover=2\n",
      "\t\t\t\t15:leaf=0.00234628934,cover=1\n",
      "\t\t\t\t16:leaf=-0.00354670081,cover=1\n",
      "\t\t4:[f93<0.0342202] yes=9,no=10,missing=9,gain=0.594651699,cover=216\n",
      "\t\t\t9:[f13<0.206837147] yes=17,no=18,missing=17,gain=0.622033656,cover=89\n",
      "\t\t\t\t17:[f11<0.582085967] yes=25,no=26,missing=25,gain=0.445600599,cover=50\n",
      "\t\t\t\t\t25:[f85<1.08144879] yes=33,no=34,missing=33,gain=0.360278398,cover=35\n",
      "\t\t\t\t\t\t33:leaf=0.000617759011,cover=31\n",
      "\t\t\t\t\t\t34:leaf=0.0874194354,cover=4\n",
      "\t\t\t\t\t26:[f36<0.290886551] yes=35,no=36,missing=35,gain=0.241788894,cover=15\n",
      "\t\t\t\t\t\t35:leaf=-0.0133506199,cover=9\n",
      "\t\t\t\t\t\t36:leaf=-0.0895126686,cover=6\n",
      "\t\t\t\t18:[f42<0.233507797] yes=27,no=28,missing=27,gain=0.506770492,cover=39\n",
      "\t\t\t\t\t27:[f0<0.208467454] yes=37,no=38,missing=37,gain=0.377019435,cover=27\n",
      "\t\t\t\t\t\t37:leaf=0.000929409463,cover=15\n",
      "\t\t\t\t\t\t38:leaf=-0.0688110888,cover=12\n",
      "\t\t\t\t\t28:[f81<0.33372128] yes=39,no=40,missing=39,gain=0.29283917,cover=12\n",
      "\t\t\t\t\t\t39:leaf=-0.130321264,cover=9\n",
      "\t\t\t\t\t\t40:leaf=-0.0170058757,cover=3\n",
      "\t\t\t10:[f89<1.66753709] yes=19,no=20,missing=19,gain=0.791586757,cover=127\n",
      "\t\t\t\t19:[f45<0.179583147] yes=29,no=30,missing=29,gain=0.643472254,cover=118\n",
      "\t\t\t\t\t29:[f10<1.98111129] yes=41,no=42,missing=41,gain=0.7415905,cover=63\n",
      "\t\t\t\t\t\t41:leaf=-0.0306014586,cover=61\n",
      "\t\t\t\t\t\t42:leaf=0.122762859,cover=2\n",
      "\t\t\t\t\t30:[f0<1.30521727] yes=43,no=44,missing=43,gain=0.53328836,cover=55\n",
      "\t\t\t\t\t\t43:leaf=0.0117897531,cover=52\n",
      "\t\t\t\t\t\t44:leaf=0.125859052,cover=3\n",
      "\t\t\t\t20:[f29<0.326189816] yes=31,no=32,missing=31,gain=0.168322802,cover=9\n",
      "\t\t\t\t\t31:leaf=0.117329329,cover=5\n",
      "\t\t\t\t\t32:[f0<-0.410036504] yes=45,no=46,missing=45,gain=0.00456920639,cover=4\n",
      "\t\t\t\t\t\t45:leaf=0.00459890254,cover=1\n",
      "\t\t\t\t\t\t46:leaf=0.0330076888,cover=3\n",
      "\t2:[f93<0.143893003] yes=5,no=6,missing=5,gain=0.482399285,cover=15\n",
      "\t\t5:[f37<0.231722444] yes=11,no=12,missing=11,gain=0.0319009647,cover=9\n",
      "\t\t\t11:[f14<0.018726591] yes=21,no=22,missing=21,gain=0.00104115158,cover=6\n",
      "\t\t\t\t21:leaf=-0.0124701345,cover=2\n",
      "\t\t\t\t22:leaf=-0.0338337198,cover=4\n",
      "\t\t\t12:[f0<2.32327747] yes=23,no=24,missing=23,gain=0.00180096237,cover=3\n",
      "\t\t\t\t23:leaf=0.0096738087,cover=2\n",
      "\t\t\t\t24:leaf=-0.00288067805,cover=1\n",
      "\t\t6:[f19<-1.20673454] yes=13,no=14,missing=13,gain=0.162120938,cover=6\n",
      "\t\t\t13:leaf=-0.0331179239,cover=2\n",
      "\t\t\t14:leaf=-0.156284809,cover=4\n",
      "\n",
      "0:[f48<1.53725326] yes=1,no=2,missing=1,gain=0.433165133,cover=239\n",
      "\t1:[f91<-0.894788384] yes=3,no=4,missing=3,gain=0.476402074,cover=224\n",
      "\t\t3:[f12<1.06312287] yes=7,no=8,missing=7,gain=0.394924253,cover=27\n",
      "\t\t\t7:[f22<-0.623197079] yes=13,no=14,missing=13,gain=0.156072631,cover=25\n",
      "\t\t\t\t13:[f3<0.224167556] yes=21,no=22,missing=21,gain=0.00463949889,cover=5\n",
      "\t\t\t\t\t21:leaf=-0.0341944434,cover=4\n",
      "\t\t\t\t\t22:leaf=-0.00520177791,cover=1\n",
      "\t\t\t\t14:[f17<-0.186117321] yes=23,no=24,missing=23,gain=0.0837600976,cover=20\n",
      "\t\t\t\t\t23:[f10<-0.432072639] yes=35,no=36,missing=35,gain=0.0237409212,cover=9\n",
      "\t\t\t\t\t\t35:leaf=0.0209787786,cover=3\n",
      "\t\t\t\t\t\t36:leaf=-0.00804082863,cover=6\n",
      "\t\t\t\t\t24:[f49<-0.171793967] yes=37,no=38,missing=37,gain=0.0203257054,cover=11\n",
      "\t\t\t\t\t\t37:leaf=0.0232005529,cover=6\n",
      "\t\t\t\t\t\t38:leaf=0.0556871817,cover=5\n",
      "\t\t\t8:leaf=0.129196897,cover=2\n",
      "\t\t4:[f13<-1.97098994] yes=9,no=10,missing=9,gain=0.43135941,cover=197\n",
      "\t\t\t9:[f9<0.247708514] yes=15,no=16,missing=15,gain=0.20366931,cover=11\n",
      "\t\t\t\t15:[f1<-0.712970316] yes=25,no=26,missing=25,gain=0.0465241373,cover=8\n",
      "\t\t\t\t\t25:leaf=0.0138972523,cover=2\n",
      "\t\t\t\t\t26:leaf=0.0744927898,cover=6\n",
      "\t\t\t\t16:[f0<0.234562665] yes=27,no=28,missing=27,gain=0.0135562122,cover=3\n",
      "\t\t\t\t\t27:leaf=-0.00292336941,cover=2\n",
      "\t\t\t\t\t28:leaf=-0.0394974239,cover=1\n",
      "\t\t\t10:[f40<0.59781462] yes=17,no=18,missing=17,gain=0.37312603,cover=186\n",
      "\t\t\t\t17:[f8<2.32327747] yes=29,no=30,missing=29,gain=0.548648715,cover=135\n",
      "\t\t\t\t\t29:[f5<-0.212624416] yes=39,no=40,missing=39,gain=0.547860682,cover=133\n",
      "\t\t\t\t\t\t39:leaf=-0.0496813022,cover=48\n",
      "\t\t\t\t\t\t40:leaf=-0.00969959237,cover=85\n",
      "\t\t\t\t\t30:leaf=-0.155093953,cover=2\n",
      "\t\t\t\t18:[f28<1.77682269] yes=31,no=32,missing=31,gain=0.402811706,cover=51\n",
      "\t\t\t\t\t31:[f91<0.740932763] yes=41,no=42,missing=41,gain=0.239420086,cover=48\n",
      "\t\t\t\t\t\t41:leaf=-0.00123880175,cover=38\n",
      "\t\t\t\t\t\t42:leaf=0.0489891581,cover=10\n",
      "\t\t\t\t\t32:[f1<0.236502945] yes=43,no=44,missing=43,gain=0.0258750319,cover=3\n",
      "\t\t\t\t\t\t43:leaf=-0.0372129418,cover=2\n",
      "\t\t\t\t\t\t44:leaf=-0.122196801,cover=1\n",
      "\t2:[f27<0.998535633] yes=5,no=6,missing=5,gain=0.449406445,cover=15\n",
      "\t\t5:[f96<0.806262612] yes=11,no=12,missing=11,gain=0.111225933,cover=13\n",
      "\t\t\t11:[f7<-0.0127302818] yes=19,no=20,missing=19,gain=0.0382760838,cover=10\n",
      "\t\t\t\t19:leaf=-0.0254855696,cover=3\n",
      "\t\t\t\t20:[f0<0.654233158] yes=33,no=34,missing=33,gain=0.00252862833,cover=7\n",
      "\t\t\t\t\t33:leaf=0.0135553265,cover=5\n",
      "\t\t\t\t\t34:leaf=0.000807666802,cover=2\n",
      "\t\t\t12:leaf=0.0573815182,cover=3\n",
      "\t\t6:leaf=0.145462677,cover=2\n",
      "\n",
      "0:[f19<0.845171809] yes=1,no=2,missing=1,gain=0.357293785,cover=239\n",
      "\t1:[f53<-0.850666523] yes=3,no=4,missing=3,gain=0.341503918,cover=190\n",
      "\t\t3:[f81<0.175357312] yes=7,no=8,missing=7,gain=0.419873685,cover=30\n",
      "\t\t\t7:[f33<-0.13639906] yes=15,no=16,missing=15,gain=0.0874330699,cover=18\n",
      "\t\t\t\t15:[f1<-0.141395941] yes=29,no=30,missing=29,gain=0.0045494996,cover=4\n",
      "\t\t\t\t\t29:leaf=-0.0420302115,cover=2\n",
      "\t\t\t\t\t30:leaf=-0.0125538763,cover=2\n",
      "\t\t\t\t16:[f21<0.157167464] yes=31,no=32,missing=31,gain=0.0253729019,cover=14\n",
      "\t\t\t\t\t31:[f15<-0.266558975] yes=51,no=52,missing=51,gain=0.00326440483,cover=8\n",
      "\t\t\t\t\t\t51:leaf=0.00737674301,cover=2\n",
      "\t\t\t\t\t\t52:leaf=0.0266003031,cover=6\n",
      "\t\t\t\t\t32:[f3<0.165892497] yes=53,no=54,missing=53,gain=0.00698499475,cover=6\n",
      "\t\t\t\t\t\t53:leaf=0.00734047871,cover=3\n",
      "\t\t\t\t\t\t54:leaf=-0.0104270699,cover=3\n",
      "\t\t\t8:[f3<-0.286385119] yes=17,no=18,missing=17,gain=0.167502463,cover=12\n",
      "\t\t\t\t17:leaf=-0.101353534,cover=6\n",
      "\t\t\t\t18:[f1<-0.154370725] yes=33,no=34,missing=33,gain=0.014328938,cover=6\n",
      "\t\t\t\t\t33:leaf=0.00340919499,cover=1\n",
      "\t\t\t\t\t34:[f1<1.10476482] yes=55,no=56,missing=55,gain=0.000550664961,cover=5\n",
      "\t\t\t\t\t\t55:leaf=-0.0377624296,cover=3\n",
      "\t\t\t\t\t\t56:leaf=-0.0142861186,cover=2\n",
      "\t\t4:[f18<0.250030547] yes=9,no=10,missing=9,gain=0.449564755,cover=160\n",
      "\t\t\t9:[f8<2.32053375] yes=19,no=20,missing=19,gain=0.475588858,cover=96\n",
      "\t\t\t\t19:[f11<-0.616258979] yes=35,no=36,missing=35,gain=0.322793454,cover=94\n",
      "\t\t\t\t\t35:[f89<0.456799835] yes=57,no=58,missing=57,gain=0.250692487,cover=19\n",
      "\t\t\t\t\t\t57:leaf=-0.0110192485,cover=13\n",
      "\t\t\t\t\t\t58:leaf=-0.0824890584,cover=6\n",
      "\t\t\t\t\t36:[f55<-0.0165343918] yes=59,no=60,missing=59,gain=0.291357696,cover=75\n",
      "\t\t\t\t\t\t59:leaf=-0.0151501717,cover=32\n",
      "\t\t\t\t\t\t60:leaf=0.0221676398,cover=43\n",
      "\t\t\t\t20:leaf=-0.124075167,cover=2\n",
      "\t\t\t10:[f54<0.39327985] yes=21,no=22,missing=21,gain=0.529366612,cover=64\n",
      "\t\t\t\t21:[f89<0.190876871] yes=37,no=38,missing=37,gain=0.321308732,cover=41\n",
      "\t\t\t\t\t37:[f12<0.644348025] yes=61,no=62,missing=61,gain=0.131690234,cover=28\n",
      "\t\t\t\t\t\t61:leaf=0.0396955907,cover=19\n",
      "\t\t\t\t\t\t62:leaf=-0.00362633332,cover=9\n",
      "\t\t\t\t\t38:[f29<0.48608008] yes=63,no=64,missing=63,gain=0.327668071,cover=13\n",
      "\t\t\t\t\t\t63:leaf=0.0432057939,cover=9\n",
      "\t\t\t\t\t\t64:leaf=0.147102341,cover=4\n",
      "\t\t\t\t22:[f58<-0.743087649] yes=39,no=40,missing=39,gain=0.363321155,cover=23\n",
      "\t\t\t\t\t39:[f5<1.32749581] yes=65,no=66,missing=65,gain=0.043666631,cover=5\n",
      "\t\t\t\t\t\t65:leaf=0.065930143,cover=4\n",
      "\t\t\t\t\t\t66:leaf=-0.00138832629,cover=1\n",
      "\t\t\t\t\t40:[f95<-0.911853433] yes=67,no=68,missing=67,gain=0.166324317,cover=18\n",
      "\t\t\t\t\t\t67:leaf=-0.085110195,cover=3\n",
      "\t\t\t\t\t\t68:leaf=-0.0147463148,cover=15\n",
      "\t2:[f32<0.740719736] yes=5,no=6,missing=5,gain=0.390632182,cover=49\n",
      "\t\t5:[f80<0.419250309] yes=11,no=12,missing=11,gain=0.392276347,cover=38\n",
      "\t\t\t11:[f13<0.345459431] yes=23,no=24,missing=23,gain=0.204640061,cover=20\n",
      "\t\t\t\t23:[f50<0.446100742] yes=41,no=42,missing=41,gain=0.071333684,cover=13\n",
      "\t\t\t\t\t41:[f41<0.881931424] yes=69,no=70,missing=69,gain=0.0166688338,cover=9\n",
      "\t\t\t\t\t\t69:leaf=0.00458986452,cover=6\n",
      "\t\t\t\t\t\t70:leaf=-0.0198507551,cover=3\n",
      "\t\t\t\t\t42:[f1<-0.629624784] yes=71,no=72,missing=71,gain=0.00120361894,cover=4\n",
      "\t\t\t\t\t\t71:leaf=0.0112567376,cover=1\n",
      "\t\t\t\t\t\t72:leaf=0.0437782928,cover=3\n",
      "\t\t\t\t24:[f30<0.148020133] yes=43,no=44,missing=43,gain=0.0331871659,cover=7\n",
      "\t\t\t\t\t43:leaf=-0.0226601772,cover=4\n",
      "\t\t\t\t\t44:leaf=-0.0709204078,cover=3\n",
      "\t\t\t12:[f63<0.874127865] yes=25,no=26,missing=25,gain=0.128227472,cover=18\n",
      "\t\t\t\t25:[f18<-2.29182482] yes=45,no=46,missing=45,gain=0.00781166553,cover=11\n",
      "\t\t\t\t\t45:leaf=-0.0250635725,cover=1\n",
      "\t\t\t\t\t46:leaf=-0.0963605791,cover=10\n",
      "\t\t\t\t26:[f12<0.628071904] yes=47,no=48,missing=47,gain=0.0111940131,cover=7\n",
      "\t\t\t\t\t47:leaf=-0.038038902,cover=6\n",
      "\t\t\t\t\t48:leaf=-0.00198706076,cover=1\n",
      "\t\t6:[f11<-0.291386425] yes=13,no=14,missing=13,gain=0.176151514,cover=11\n",
      "\t\t\t13:[f29<0.0918217599] yes=27,no=28,missing=27,gain=0.0302849971,cover=7\n",
      "\t\t\t\t27:[f11<-1.6342411] yes=49,no=50,missing=49,gain=0.00397991017,cover=5\n",
      "\t\t\t\t\t49:leaf=-0.026038399,cover=3\n",
      "\t\t\t\t\t50:leaf=-0.00570994057,cover=2\n",
      "\t\t\t\t28:leaf=0.0171581097,cover=2\n",
      "\t\t\t14:leaf=0.0639554113,cover=4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dump = bst.get_dump(with_stats=True)\n",
    "for tree in dump:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ initial cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using XGBoost CV\n",
    "+ set params\n",
    "+ set dtrain\n",
    "+ use large number of num_boost_round and count on early_stopping_rounds to find optimal number of rounds before reaching the maximum\n",
    "+ seed similar to train_test_splits random_state, but for running cross validation states because each train and each split is designated randomly by computer\n",
    "+ number of folds in CV\n",
    "+ set metrics used for scoring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv results   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
      "0         0.945942        0.039775        1.122408       0.059949\n",
      "best RSME score with cv :1.1224084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_results = xgb.cv(\n",
    "    PARAMETERS,\n",
    "    data_train,\n",
    "    num_boost_round=999,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "print(\"cv results{}\".format(cv_results))\n",
    "print(f\"best RSME score with cv :{cv_results['test-rmse-mean'].min()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ cv return table where rows correspond number of boosting trees used\n",
    "+ 4 columns correspond to mean and standard deviation for both train and test\n",
    "+ goal in cv to optimize scoring for eval_metric param during cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize max_depth and min_child_weight\n",
    "+ max_depth is maximum number of nodes allowed from root to the farthest leaf of a tree. Deeper trees can model more complex relationships by adding more nodes, but as we go deeper, splits become less relevant and are sometiems only due to noise, causing model to overfit.\n",
    "+ min_child_weight is the minimum weight(or of samples if all samples have a weight of 1) required in order to create a new node in the tree. A small min_child_weight allows the alogorithm to create children that corresponds to fewer samples, thus allowing for more complex trees, but again more likely to overfit.\n",
    "+ important to tune together to find good trade-off between model bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "can try wider intervals with larger step between each value then narrow it down.\n",
    "\n",
    "better try that myself to find optimal ranges\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "gridsearch_params = [\n",
    "    (max_depth,min_child_weight)\n",
    "    for max_depth in range(9,13)\n",
    "    for min_child_weight in range(5,8)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ make list containing all combinations of max_depth/min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\tRMSE 1.1315176 for 0\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tRMSE 1.127293 for 1\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tRMSE 1.1284930000000002 for 0\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tRMSE 1.1315456 for 0\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tRMSE 1.1201440000000003 for 3\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tRMSE 1.1094518 for 3\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tRMSE 1.1347639999999999 for 0\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tRMSE 1.1205517999999999 for 3\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tRMSE 1.12721 for 1\n",
      "CV with max_depth=12, min_child_weight=5\n",
      "\tRMSE 1.133886 for 0\n",
      "CV with max_depth=12, min_child_weight=6\n",
      "\tRMSE 1.1205606000000001 for 3\n",
      "CV with max_depth=12, min_child_weight=7\n",
      "\tRMSE 1.127573 for 1\n",
      "Best params: 10, 7, RMSE: 1.1094518\n"
     ]
    }
   ],
   "source": [
    "\n",
    "min_rmse = float(\"Inf\")\n",
    "best_depth = None\n",
    "\n",
    "for max_depth,min_child_weight in gridsearch_params:\n",
    "    print(f\"CV with max_depth={max_depth}, min_child_weight={min_child_weight}\")\n",
    "\n",
    "    PARAMETERS['max_depth'] = max_depth\n",
    "    PARAMETERS['min_child_weight'] = min_child_weight\n",
    "\n",
    "    cv_results = xgb.cv(\n",
    "        PARAMETERS,\n",
    "        data_train,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10,\n",
    "    )\n",
    "\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(f\"\\tRMSE {mean_rmse} for {boost_rounds}\")\n",
    "\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_depth = (max_depth,min_child_weight)\n",
    "\n",
    "print(f\"Best params: {best_depth[0]}, {best_depth[1]}, RMSE: {min_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ assign min rmse to infinite\n",
    "+ loop through gridseach params(need to find custom optimal intervals from wide range then narrow down)\n",
    "+ print current max_depth and min_child_weight iteration\n",
    "+ update max_depth, min_child_weight to params\n",
    "+ run cross validation for current iteration of max_depth,min_child_weight\n",
    "+ aggregate test-rmse-mean minimum value and positional index of that value in array\n",
    "+ print optimal scoring in array rounds per iteration\n",
    "+ if current iteration of mean_rmse is less than previous iteration of mean_rmse, aggregate as min_rmse\n",
    "+ print best params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize for subsample and colsample_bytree\n",
    "+ these are parameters that control the sampling of dataset done at each boosting round\n",
    "+ thus can build tree on slightly different data at each step making it less likely to overfit to any single sample or feature\n",
    "+ subsample corresponds to the fraction of observations (the rows) to subsample at each step. default 1, meaning all rows.\n",
    "+ colsample_bytree corresponds to fraction of features(the columns) to use. default is 1, meaning all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tRMSE 1.1275727999999998 for 1 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tRMSE 1.1458746000000002 for 2 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tRMSE 1.1143754 for 1 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tRMSE 1.1501571999999998 for 0 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tRMSE 1.1375574 for 0 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tRMSE 1.1321413999999999 for 1 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tRMSE 1.1473356 for 0 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tRMSE 1.137143 for 1 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tRMSE 1.1077748 for 1 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tRMSE 1.1105392 for 1 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tRMSE 1.1170624 for 1 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tRMSE 1.123719 for 2 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tRMSE 1.1515416 for 0 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tRMSE 1.157096 for 0 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tRMSE 1.1482568 for 2 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tRMSE 1.1422029999999999 for 1 rounds\n",
      "Best params: 0.8, 1.0, RMSE: 1.1077748\n"
     ]
    }
   ],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_samples = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(subsample,colsample)) # We update our parameters\n",
    "\n",
    "    PARAMETERS['subsample'] = subsample\n",
    "    PARAMETERS['colsample_bytree'] = colsample    # Run CV\n",
    "\n",
    "    cv_results = xgb.cv(\n",
    "        PARAMETERS,\n",
    "        data_train,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )    # Update best score\n",
    "\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_samples = (subsample,colsample)\n",
    "        \n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_samples[0], best_samples[1], min_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ assign min rmse to infinite\n",
    "+ We start by the largest values and go down to the smallest\n",
    "+ print current subsample and colsample iteration\n",
    "+ update subsample, colsample to params\n",
    "+ run cross validation for current iteration of subsample, colsample\n",
    "+ aggregate test-rmse-mean minimum value and positional index of that value in array\n",
    "+ print optimal scoring in array rounds per iteration\n",
    "+ if current iteration of mean_rmse is less than previous iteration of mean_rmse, aggregate as min_rmse\n",
    "+ print best params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best params for Learning rate (eta)\n",
    "+ corresponds to the shrinkage of weights associated to features after each round, in other words it defines the amount of \"correction\" we make at each step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.3\n",
      "\tRMSE 1.1422029999999999 for 1\n",
      "CV with eta=0.2\n",
      "\tRMSE 1.1280382 for 1\n",
      "CV with eta=0.1\n",
      "\tRMSE 1.1313102 for 9\n",
      "CV with eta=0.05\n",
      "\tRMSE 1.1173942000000001 for 20\n",
      "CV with eta=0.01\n",
      "\tRMSE 1.0967046 for 91\n",
      "CV with eta=0.005\n",
      "\tRMSE 1.0981802 for 218\n",
      "Best params: 0.01, RSME: 1.0967046\n"
     ]
    }
   ],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_eta = None\n",
    "\n",
    "for eta in [.3,.2,.1,.05,.01,.005]:\n",
    "    print(f\"CV with eta={eta}\")\n",
    "\n",
    "    PARAMETERS['eta'] = eta\n",
    "    cv_results = xgb.cv(\n",
    "        PARAMETERS,\n",
    "        data_train,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10,\n",
    "    )\n",
    "\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(f\"\\tRMSE {mean_rmse} for {boost_rounds}\")\n",
    "\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_eta = eta\n",
    "\n",
    "print(f\"Best params: {best_eta}, RSME: {min_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ assign min rmse to infinite\n",
    "+ loop through conventional learning rate (eta)\n",
    "+ print current eta iteration\n",
    "+ update eta to params\n",
    "+ run cross validation for current iteration of eta\n",
    "+ aggregate test-rmse-mean minimum value and positional index of that value in array\n",
    "+  print optimal scoring in array rounds per iteration\n",
    "+ if current iteration of mean_rmse is less than previous iteration of mean_rmse, aggregate as min_rmse\n",
    "+ print best params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ training and best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': best_depth[0],\n",
    "    'min_child_weight': best_depth[1],\n",
    "    'eta': best_eta,\n",
    "    'subsample': best_samples[0],\n",
    "    'colsample_bytree': best_samples[1],\n",
    "    'objective':'reg:squarederror',\n",
    "    'eval_metric':'rmse'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ optimal parameters for xgboost API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:1.2294\n",
      "Will train until Test-rmse hasn't improved in 10 rounds.\n",
      "[1]\tTest-rmse:1.2288\n",
      "[2]\tTest-rmse:1.22828\n",
      "[3]\tTest-rmse:1.22761\n",
      "[4]\tTest-rmse:1.22805\n",
      "[5]\tTest-rmse:1.22871\n",
      "[6]\tTest-rmse:1.2274\n",
      "[7]\tTest-rmse:1.2263\n",
      "[8]\tTest-rmse:1.22646\n",
      "[9]\tTest-rmse:1.22619\n",
      "[10]\tTest-rmse:1.22439\n",
      "[11]\tTest-rmse:1.2253\n",
      "[12]\tTest-rmse:1.22572\n",
      "[13]\tTest-rmse:1.22391\n",
      "[14]\tTest-rmse:1.22186\n",
      "[15]\tTest-rmse:1.22128\n",
      "[16]\tTest-rmse:1.22024\n",
      "[17]\tTest-rmse:1.22\n",
      "[18]\tTest-rmse:1.22123\n",
      "[19]\tTest-rmse:1.22112\n",
      "[20]\tTest-rmse:1.22056\n",
      "[21]\tTest-rmse:1.22085\n",
      "[22]\tTest-rmse:1.21936\n",
      "[23]\tTest-rmse:1.21895\n",
      "[24]\tTest-rmse:1.21651\n",
      "[25]\tTest-rmse:1.21719\n",
      "[26]\tTest-rmse:1.21684\n",
      "[27]\tTest-rmse:1.21547\n",
      "[28]\tTest-rmse:1.21412\n",
      "[29]\tTest-rmse:1.21334\n",
      "[30]\tTest-rmse:1.21324\n",
      "[31]\tTest-rmse:1.21166\n",
      "[32]\tTest-rmse:1.21168\n",
      "[33]\tTest-rmse:1.21144\n",
      "[34]\tTest-rmse:1.21109\n",
      "[35]\tTest-rmse:1.21104\n",
      "[36]\tTest-rmse:1.21214\n",
      "[37]\tTest-rmse:1.21209\n",
      "[38]\tTest-rmse:1.21222\n",
      "[39]\tTest-rmse:1.21067\n",
      "[40]\tTest-rmse:1.21029\n",
      "[41]\tTest-rmse:1.21132\n",
      "[42]\tTest-rmse:1.2119\n",
      "[43]\tTest-rmse:1.21212\n",
      "[44]\tTest-rmse:1.21107\n",
      "[45]\tTest-rmse:1.21063\n",
      "[46]\tTest-rmse:1.21073\n",
      "[47]\tTest-rmse:1.21163\n",
      "[48]\tTest-rmse:1.2112\n",
      "[49]\tTest-rmse:1.21247\n",
      "[50]\tTest-rmse:1.21051\n",
      "Stopping. Best iteration:\n",
      "[40]\tTest-rmse:1.21029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    data_train,\n",
    "    num_boost_round=999,\n",
    "    evals=[(data_test,\"Test\")],\n",
    "    early_stopping_rounds=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 1.21 in 41 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RMSE: {:.2f} in {} rounds\".format(model.best_score,model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ if early stopping occurs, the model will have three additional fields .best_score, .best_iteration, and .best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = model.best_iteration + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ allow for model best_iteration inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:1.2294\n",
      "[1]\tTest-rmse:1.2288\n",
      "[2]\tTest-rmse:1.22828\n",
      "[3]\tTest-rmse:1.22761\n",
      "[4]\tTest-rmse:1.22805\n",
      "[5]\tTest-rmse:1.22871\n",
      "[6]\tTest-rmse:1.2274\n",
      "[7]\tTest-rmse:1.2263\n",
      "[8]\tTest-rmse:1.22646\n",
      "[9]\tTest-rmse:1.22619\n",
      "[10]\tTest-rmse:1.22439\n",
      "[11]\tTest-rmse:1.2253\n",
      "[12]\tTest-rmse:1.22572\n",
      "[13]\tTest-rmse:1.22391\n",
      "[14]\tTest-rmse:1.22186\n",
      "[15]\tTest-rmse:1.22128\n",
      "[16]\tTest-rmse:1.22024\n",
      "[17]\tTest-rmse:1.22\n",
      "[18]\tTest-rmse:1.22123\n",
      "[19]\tTest-rmse:1.22112\n",
      "[20]\tTest-rmse:1.22056\n",
      "[21]\tTest-rmse:1.22085\n",
      "[22]\tTest-rmse:1.21936\n",
      "[23]\tTest-rmse:1.21895\n",
      "[24]\tTest-rmse:1.21651\n",
      "[25]\tTest-rmse:1.21719\n",
      "[26]\tTest-rmse:1.21684\n",
      "[27]\tTest-rmse:1.21547\n",
      "[28]\tTest-rmse:1.21412\n",
      "[29]\tTest-rmse:1.21334\n",
      "[30]\tTest-rmse:1.21324\n",
      "[31]\tTest-rmse:1.21166\n",
      "[32]\tTest-rmse:1.21168\n",
      "[33]\tTest-rmse:1.21144\n",
      "[34]\tTest-rmse:1.21109\n",
      "[35]\tTest-rmse:1.21104\n",
      "[36]\tTest-rmse:1.21214\n",
      "[37]\tTest-rmse:1.21209\n",
      "[38]\tTest-rmse:1.21222\n",
      "[39]\tTest-rmse:1.21067\n",
      "[40]\tTest-rmse:1.21029\n"
     ]
    }
   ],
   "source": [
    "best_model = xgb.train(\n",
    "    params,\n",
    "    data_train,\n",
    "    num_boost_round = num_boost_round,\n",
    "    evals=[(data_test,\"Test\")]\n",
    "        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train data with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save_model(\"xgbregression.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(\"xgbregression.model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_API = loaded_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_API.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ make predictions from saved model to prevent overtraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_API = pd.DataFrame(predictions_API)\n",
    "predictions_API['y_test'] = y_test\n",
    "predictions_API['diff'] = predictions_API.y_test - predictions_API[0]\n",
    "predictions_API['exp'] = (predictions_API.y_test - predictions_API[0])**2\n",
    "mean_squared_error = predictions_API['exp'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ manual calculations for mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error is : 1.4647957037250146\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean squared error is : {mean_squared_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "#ax.scatter(pred[0], color='r')\n",
    "ax.scatter(predictions_API[0] ,predictions_API['y_test'], color='b')\n",
    "ax.set_xlabel('preds')\n",
    "ax.set_ylabel('y_test')\n",
    "ax.set_title('scatter plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ plotting out y_test juxtaposed to pred via xgboost API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = timer(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# example_1('reg:linear',\"mse\",999,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer(start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Sklearn xgboost wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = timer(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, pred = algorithm_pipeline(X_train, X_test, y_train, y_test, model, \n",
    "#                                   param_grid, cv=5)\n",
    "\n",
    "# # # Root Mean Squared Error\n",
    "# print(np.sqrt(-model.best_score_))\n",
    "# print(model.best_params_) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ running algorithm pipeline of custom function for grid seach fine tuning parameters for xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(nthread=-1,objective='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid = GridSearchCV(xgb,param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timer(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bynode=1,\n",
       "                                    colsample_bytree=1, gamma=0,\n",
       "                                    importance_type='gain', learning_rate=0.1,\n",
       "                                    max_delta_step=0, max_depth=3,\n",
       "                                    min_child_weight=1, missing=None,\n",
       "                                    n_estimators=100, n_jobs=1, nthread=-1,\n",
       "                                    objective='reg:squarederror',\n",
       "                                    random_state=0, reg_alpha...\n",
       "                                    scale_pos_weight=1, seed=None, silent=None,\n",
       "                                    subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'colsample_bytree': [0.7, 0.8],\n",
       "                         'max_depth': [15, 20, 25],\n",
       "                         'n_estimators': [400, 700, 1000],\n",
       "                         'reg_alpha': [1.1, 1.2, 1.3],\n",
       "                         'reg_lambda': [1.1, 1.2, 1.3],\n",
       "                         'subsample': [0.7, 0.8, 0.9]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ fitting train data to grid search tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 21 minutes and 2.12 seconds.\n"
     ]
    }
   ],
   "source": [
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = grid.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.13816149734654393\n",
      "1.593834510473967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "print(r2_score(y_test,grid.best_estimator_.predict(X_test)))\n",
    "print(mean_squared_error(y_test,grid.best_estimator_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ mean sqaured error scoring and root squared scoring available from sklearn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred['y_test'] = y_test\n",
    "pred['diff'] = pred['y_test'] - pred[0]\n",
    "pred['exp'] = (pred.y_test - pred[0])**2\n",
    "avg_pred = pred.exp.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Manual calculations of mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "#ax.scatter(pred[0], color='r')\n",
    "ax.scatter(pred[0] ,pred['y_test'], color='b')\n",
    "ax.set_xlabel('preds')\n",
    "ax.set_ylabel('y_test')\n",
    "ax.set_title('scatter plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ plotting out y_test juxtaposed to preds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ link for sklearn wrapper; https://www.kaggle.com/omarito/gridsearchcv-xgbregressor-0-556-lb\n",
    "+ link for xgboost api; https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>y_test</th>\n",
       "      <th>diff</th>\n",
       "      <th>exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.150999</td>\n",
       "      <td>0.035361</td>\n",
       "      <td>-0.115638</td>\n",
       "      <td>0.013372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516907</td>\n",
       "      <td>0.333457</td>\n",
       "      <td>-0.183450</td>\n",
       "      <td>0.033654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.039186</td>\n",
       "      <td>0.200642</td>\n",
       "      <td>0.239828</td>\n",
       "      <td>0.057517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.235619</td>\n",
       "      <td>0.791082</td>\n",
       "      <td>0.555463</td>\n",
       "      <td>0.308539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162564</td>\n",
       "      <td>-0.919053</td>\n",
       "      <td>-1.081617</td>\n",
       "      <td>1.169894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.226028</td>\n",
       "      <td>0.879029</td>\n",
       "      <td>1.105057</td>\n",
       "      <td>1.221150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.307716</td>\n",
       "      <td>-0.294551</td>\n",
       "      <td>-0.602267</td>\n",
       "      <td>0.362726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.251122</td>\n",
       "      <td>0.784034</td>\n",
       "      <td>1.035157</td>\n",
       "      <td>1.071549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.277158</td>\n",
       "      <td>-0.582072</td>\n",
       "      <td>-0.859230</td>\n",
       "      <td>0.738276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.125176</td>\n",
       "      <td>-0.758483</td>\n",
       "      <td>-0.633307</td>\n",
       "      <td>0.401078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.497773</td>\n",
       "      <td>0.318923</td>\n",
       "      <td>0.816695</td>\n",
       "      <td>0.666991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.617246</td>\n",
       "      <td>-0.847800</td>\n",
       "      <td>-1.465046</td>\n",
       "      <td>2.146360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.250519</td>\n",
       "      <td>0.112782</td>\n",
       "      <td>-0.137737</td>\n",
       "      <td>0.018971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.186880</td>\n",
       "      <td>-1.344364</td>\n",
       "      <td>-1.157484</td>\n",
       "      <td>1.339770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.375201</td>\n",
       "      <td>1.042920</td>\n",
       "      <td>1.418122</td>\n",
       "      <td>2.011069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.525334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525334</td>\n",
       "      <td>0.275975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.424384</td>\n",
       "      <td>0.465580</td>\n",
       "      <td>0.041197</td>\n",
       "      <td>0.001697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.520638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.520638</td>\n",
       "      <td>0.271064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.105763</td>\n",
       "      <td>-0.912076</td>\n",
       "      <td>-0.806312</td>\n",
       "      <td>0.650140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.192716</td>\n",
       "      <td>0.234192</td>\n",
       "      <td>0.041476</td>\n",
       "      <td>0.001720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.299733</td>\n",
       "      <td>0.072886</td>\n",
       "      <td>-0.226846</td>\n",
       "      <td>0.051459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.506283</td>\n",
       "      <td>1.070399</td>\n",
       "      <td>0.564116</td>\n",
       "      <td>0.318227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.139637</td>\n",
       "      <td>1.545455</td>\n",
       "      <td>1.405818</td>\n",
       "      <td>1.976323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.482460</td>\n",
       "      <td>1.529052</td>\n",
       "      <td>2.011512</td>\n",
       "      <td>4.046180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.110382</td>\n",
       "      <td>-0.998930</td>\n",
       "      <td>-0.888548</td>\n",
       "      <td>0.789517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.216173</td>\n",
       "      <td>-3.589316</td>\n",
       "      <td>-3.805489</td>\n",
       "      <td>14.481745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.044786</td>\n",
       "      <td>1.339124</td>\n",
       "      <td>0.294338</td>\n",
       "      <td>0.086635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.179592</td>\n",
       "      <td>-0.388224</td>\n",
       "      <td>-0.567815</td>\n",
       "      <td>0.322414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.283798</td>\n",
       "      <td>-1.121002</td>\n",
       "      <td>-0.837204</td>\n",
       "      <td>0.700911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.566327</td>\n",
       "      <td>0.893471</td>\n",
       "      <td>0.327144</td>\n",
       "      <td>0.107023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.396399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.396399</td>\n",
       "      <td>0.157132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.174653</td>\n",
       "      <td>-2.886516</td>\n",
       "      <td>-3.061170</td>\n",
       "      <td>9.370760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.489900</td>\n",
       "      <td>-0.278219</td>\n",
       "      <td>0.211680</td>\n",
       "      <td>0.044809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.334076</td>\n",
       "      <td>4.700855</td>\n",
       "      <td>5.034930</td>\n",
       "      <td>25.350524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.187363</td>\n",
       "      <td>1.129738</td>\n",
       "      <td>1.317101</td>\n",
       "      <td>1.734754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.067481</td>\n",
       "      <td>0.275049</td>\n",
       "      <td>0.342530</td>\n",
       "      <td>0.117327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.200604</td>\n",
       "      <td>-0.260320</td>\n",
       "      <td>-0.059716</td>\n",
       "      <td>0.003566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.090558</td>\n",
       "      <td>-0.037707</td>\n",
       "      <td>-1.128266</td>\n",
       "      <td>1.272983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.268112</td>\n",
       "      <td>-0.229659</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.001479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.060123</td>\n",
       "      <td>0.277557</td>\n",
       "      <td>0.217435</td>\n",
       "      <td>0.047278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.106429</td>\n",
       "      <td>-0.033069</td>\n",
       "      <td>0.073361</td>\n",
       "      <td>0.005382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.371214</td>\n",
       "      <td>-0.533881</td>\n",
       "      <td>-0.905095</td>\n",
       "      <td>0.819197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.498703</td>\n",
       "      <td>0.426621</td>\n",
       "      <td>0.925324</td>\n",
       "      <td>0.856224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.587518</td>\n",
       "      <td>1.391650</td>\n",
       "      <td>0.804132</td>\n",
       "      <td>0.646629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.028337</td>\n",
       "      <td>-0.195008</td>\n",
       "      <td>-0.223345</td>\n",
       "      <td>0.049883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.228087</td>\n",
       "      <td>-1.767365</td>\n",
       "      <td>-1.539278</td>\n",
       "      <td>2.369377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.204783</td>\n",
       "      <td>1.084207</td>\n",
       "      <td>0.879424</td>\n",
       "      <td>0.773387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.105244</td>\n",
       "      <td>0.710620</td>\n",
       "      <td>0.605376</td>\n",
       "      <td>0.366480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.406390</td>\n",
       "      <td>-0.435299</td>\n",
       "      <td>-0.841689</td>\n",
       "      <td>0.708440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.248164</td>\n",
       "      <td>-0.272798</td>\n",
       "      <td>-0.520962</td>\n",
       "      <td>0.271401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.134061</td>\n",
       "      <td>2.111159</td>\n",
       "      <td>2.245220</td>\n",
       "      <td>5.041015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.123515</td>\n",
       "      <td>0.599800</td>\n",
       "      <td>0.476285</td>\n",
       "      <td>0.226847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.583194</td>\n",
       "      <td>0.564122</td>\n",
       "      <td>-0.019073</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.182705</td>\n",
       "      <td>-0.080515</td>\n",
       "      <td>-0.263220</td>\n",
       "      <td>0.069285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-0.223020</td>\n",
       "      <td>-0.822562</td>\n",
       "      <td>-0.599542</td>\n",
       "      <td>0.359450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.687639</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>0.135406</td>\n",
       "      <td>0.018335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.018593</td>\n",
       "      <td>-0.413534</td>\n",
       "      <td>-0.432127</td>\n",
       "      <td>0.186734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.222955</td>\n",
       "      <td>0.353496</td>\n",
       "      <td>0.130541</td>\n",
       "      <td>0.017041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-0.403470</td>\n",
       "      <td>2.345059</td>\n",
       "      <td>2.748529</td>\n",
       "      <td>7.554409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.217182</td>\n",
       "      <td>1.026856</td>\n",
       "      <td>1.244039</td>\n",
       "      <td>1.547632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    y_test      diff        exp\n",
       "0   0.150999  0.035361 -0.115638   0.013372\n",
       "1   0.516907  0.333457 -0.183450   0.033654\n",
       "2  -0.039186  0.200642  0.239828   0.057517\n",
       "3   0.235619  0.791082  0.555463   0.308539\n",
       "4   0.162564 -0.919053 -1.081617   1.169894\n",
       "5  -0.226028  0.879029  1.105057   1.221150\n",
       "6   0.307716 -0.294551 -0.602267   0.362726\n",
       "7  -0.251122  0.784034  1.035157   1.071549\n",
       "8   0.277158 -0.582072 -0.859230   0.738276\n",
       "9  -0.125176 -0.758483 -0.633307   0.401078\n",
       "10 -0.497773  0.318923  0.816695   0.666991\n",
       "11  0.617246 -0.847800 -1.465046   2.146360\n",
       "12  0.250519  0.112782 -0.137737   0.018971\n",
       "13 -0.186880 -1.344364 -1.157484   1.339770\n",
       "14 -0.375201  1.042920  1.418122   2.011069\n",
       "15 -0.525334  0.000000  0.525334   0.275975\n",
       "16  0.424384  0.465580  0.041197   0.001697\n",
       "17  0.520638  0.000000 -0.520638   0.271064\n",
       "18 -0.105763 -0.912076 -0.806312   0.650140\n",
       "19  0.192716  0.234192  0.041476   0.001720\n",
       "20  0.299733  0.072886 -0.226846   0.051459\n",
       "21  0.506283  1.070399  0.564116   0.318227\n",
       "22  0.139637  1.545455  1.405818   1.976323\n",
       "23 -0.482460  1.529052  2.011512   4.046180\n",
       "24 -0.110382 -0.998930 -0.888548   0.789517\n",
       "25  0.216173 -3.589316 -3.805489  14.481745\n",
       "26  1.044786  1.339124  0.294338   0.086635\n",
       "27  0.179592 -0.388224 -0.567815   0.322414\n",
       "28 -0.283798 -1.121002 -0.837204   0.700911\n",
       "29  0.566327  0.893471  0.327144   0.107023\n",
       "30  0.396399  0.000000 -0.396399   0.157132\n",
       "31  0.174653 -2.886516 -3.061170   9.370760\n",
       "32 -0.489900 -0.278219  0.211680   0.044809\n",
       "33 -0.334076  4.700855  5.034930  25.350524\n",
       "34 -0.187363  1.129738  1.317101   1.734754\n",
       "35 -0.067481  0.275049  0.342530   0.117327\n",
       "36 -0.200604 -0.260320 -0.059716   0.003566\n",
       "37  1.090558 -0.037707 -1.128266   1.272983\n",
       "38 -0.268112 -0.229659  0.038453   0.001479\n",
       "39  0.060123  0.277557  0.217435   0.047278\n",
       "40 -0.106429 -0.033069  0.073361   0.005382\n",
       "41  0.371214 -0.533881 -0.905095   0.819197\n",
       "42 -0.498703  0.426621  0.925324   0.856224\n",
       "43  0.587518  1.391650  0.804132   0.646629\n",
       "44  0.028337 -0.195008 -0.223345   0.049883\n",
       "45 -0.228087 -1.767365 -1.539278   2.369377\n",
       "46  0.204783  1.084207  0.879424   0.773387\n",
       "47  0.105244  0.710620  0.605376   0.366480\n",
       "48  0.406390 -0.435299 -0.841689   0.708440\n",
       "49  0.248164 -0.272798 -0.520962   0.271401\n",
       "50 -0.134061  2.111159  2.245220   5.041015\n",
       "51  0.123515  0.599800  0.476285   0.226847\n",
       "52  0.583194  0.564122 -0.019073   0.000364\n",
       "53  0.182705 -0.080515 -0.263220   0.069285\n",
       "54 -0.223020 -0.822562 -0.599542   0.359450\n",
       "55  0.687639  0.823045  0.135406   0.018335\n",
       "56  0.018593 -0.413534 -0.432127   0.186734\n",
       "57  0.222955  0.353496  0.130541   0.017041\n",
       "58 -0.403470  2.345059  2.748529   7.554409\n",
       "59 -0.217182  1.026856  1.244039   1.547632"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Predictions generated from sklearn wraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.593834510473967"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ manualy calculated mean squared error of regression model from sklearn wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
