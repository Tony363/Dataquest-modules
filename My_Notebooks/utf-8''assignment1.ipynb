{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Manel Mahroug\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Visualization I \n",
    "## School of Information, University of Michigan\n",
    "\n",
    "## Week 1: \n",
    "- Domain identification vs Abstract Task extraction\n",
    "- Pandas Review \n",
    "\n",
    "## Assignment Overview\n",
    "### The objectives for this week are for you to:\n",
    "\n",
    "- Review, reflect, and apply the concepts of Domain Tasks and Abstract Tasks. Specifically, given a real context, identify the expert's goals and then abstract the visualization tasks. \n",
    "\n",
    "<img src=\"assets/domain-abstraction.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "- Review and evaluate the domain of [Pandas](https://pandas.pydata.org/) as a tool for reading, manipulating, and analyzing datasets in Python.\n",
    "\n",
    "### The total score of this assignment will be 100 points consisting of:\n",
    "- Case study reflection: Car congestion and crash rates (20 points)\n",
    "- Pandas programming exercise (80 points)\n",
    "\n",
    "\n",
    "### Resources:\n",
    "- We're going to be recreating parts of this article by [CMAP](https://www.cmap.illinois.gov/) available [online](https://www.cmap.illinois.gov/updates/all/-/asset_publisher/UIMfSLnFfMB6/content/crash-scans-show-relationship-between-congestion-and-crash-rates) (CMAP, 2016)  \n",
    "- We'll need the datasets from the city of Chicago. We have downloaded a subset to the local folder [/assets](assets/)\n",
    "    - If you're curious, the original dataset can be found on [Chicago Data Portal](https://data.cityofchicago.org/)\n",
    "        - [Chicago Traffic Tracker - Historical Congestion Estimates by Segment - 2011-2018](https://data.cityofchicago.org/Transportation/Chicago-Traffic-Tracker-Historical-Congestion-Esti/77hq-huss)\n",
    "        - [Traffic Crashes - Crashes](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if)\n",
    "- Altair\n",
    "    - We will use a python library called [Altair](https://altair-viz.github.io/) for the visualizations. Don't worry about understanding this code. You will only need to prepare the data for the visualization in Pandas. If you do it correctly, our code will produce the visualization for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Domain identification vs Abstract Task extraction (20 points)\n",
    "Read the following article by CMAP [Crash scans show the relationship between congestion and crash rates](https://www.cmap.illinois.gov/updates/all/-/asset_publisher/UIMfSLnFfMB6/content/crash-scans-show-relationship-between-congestion-and-crash-rates) and answer the following questions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Briefly describe who you think performed this analysis. What is their expertise? What is their goal for the article? Give 3 examples of domain tasks featured in the article. (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9c4d5f0e75443aa37e45648d0da2c137",
     "grade": true,
     "grade_id": "cell-d5cc91ff23d1fd3d",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Who performed the analysis: most likely data scientists working at The Chicago Metropolitan Agency for Planning.\n",
    "\n",
    "Their expertise: the data scientists who performed the analysis must have been skilled in statistical knowledge, data modeling, and data visualization. They also must have had some domain specific knowledge such as urban planning or transportation.\n",
    "\n",
    "Their goal: to determine underlying problems at particular locations to help planners and engineers improve areas with the worst performance.   \n",
    "\n",
    "Domain tasks:\n",
    "\n",
    "1. What is the relationship between congestion(traffic volume)and crash rates on expressways?\n",
    "2. What areas on the expressway have the highest crash rates?\n",
    "3. How do fatalities and serious injuries rates vary between expressways and arterials?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  For each domain task describe the abstract task (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "97e0177cfa416088176c7eca5d75b5ec",
     "grade": true,
     "grade_id": "cell-06458778598db3cb",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "These abstract tasks correspond to the domain tasks listed in the cell above, respectively.\n",
    "\n",
    "Abstract task 1: find the correlation between 2 quantitative variables.<br>\n",
    "Abstract task 2: find sums of quantitative variables.<br>\n",
    "Abstract task 3: find differences between 2 quantitative variables.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Pandas programming exercise (80 points)\n",
    "We have provided some code to create visualizations based on these two datasets:\n",
    "1. [Historic Congestion](assets/Pulaski.small.csv.gz) \n",
    "2. [Traffic Crashes](assets/Traffic.Crashes.csv.gz)\n",
    "\n",
    "Complete each assignment function and run each cell to generate the final visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RendererRegistry.enable('default')"
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enable correct rendering\n",
    "alt.renderers.enable('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DataTransformerRegistry.enable('json')"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uses intermediate json files to speed things up\n",
    "alt.data_transformers.enable('json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART A: Historic Congestion ( 55 points)\n",
    "For parts 2.1 to 2.5 we will use the Historic Congestion dataset. This dataset contains measures of speed for different segments. For this subsample, the available measures are limited to traffic on Pulaski Road in 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Read and resample (15 points)\n",
    "Complete the `read_csv` and `get_group_first_row` functions.\n",
    "Since our dataset is large we want to only grab one measurement per hour for each segment. To do this, we will resample by selecting the first measure for each month, day, hour on each segment. Complete the `get_group_first_row` function to achieve this. Note that the file we are loading is compressed--depending on how you load the file, this may or may not make a difference ([you'll want to look at the API documents](https://pandas.pydata.org/pandas-docs/stable/reference/index.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    \"\"\"Read the csv file from filename (uncompress 'gz' if needed)\n",
    "    return the dataframe resulting from reading the columns\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(118312, 48)\n"
    }
   ],
   "source": [
    "# Save the congestion dataframe on hist_con\n",
    "hist_con = read_csv('/home/tony/Desktop/github_repos/Dataquest-modules/utf-8Traffic.Crashes.csv.gz')\n",
    "print(hist_con.shape)\n",
    "# assert hist_con.shape == (3195450, 10)\n",
    "# assert list(hist_con.columns) == ['TIME','SEGMENT_ID','SPEED','STREET','DIRECTION','FROM_STREET','TO_STREET','HOUR','DAY_OF_WEEK','MONTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RD_NO</th>\n      <th>CRASH_DATE_EST_I</th>\n      <th>CRASH_DATE</th>\n      <th>POSTED_SPEED_LIMIT</th>\n      <th>TRAFFIC_CONTROL_DEVICE</th>\n      <th>DEVICE_CONDITION</th>\n      <th>WEATHER_CONDITION</th>\n      <th>LIGHTING_CONDITION</th>\n      <th>FIRST_CRASH_TYPE</th>\n      <th>TRAFFICWAY_TYPE</th>\n      <th>...</th>\n      <th>INJURIES_NON_INCAPACITATING</th>\n      <th>INJURIES_REPORTED_NOT_EVIDENT</th>\n      <th>INJURIES_NO_INDICATION</th>\n      <th>INJURIES_UNKNOWN</th>\n      <th>CRASH_HOUR</th>\n      <th>CRASH_DAY_OF_WEEK</th>\n      <th>CRASH_MONTH</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>LOCATION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>JC111663</td>\n      <td>NaN</td>\n      <td>01/01/2019 12:00:00 AM</td>\n      <td>35</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>UNKNOWN</td>\n      <td>UNKNOWN</td>\n      <td>PARKED MOTOR VEHICLE</td>\n      <td>NOT DIVIDED</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>41.793502</td>\n      <td>-87.586407</td>\n      <td>POINT (-87.586406738035 41.793502271093)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>JC100635</td>\n      <td>Y</td>\n      <td>01/01/2019 12:00:00 AM</td>\n      <td>30</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>CLEAR</td>\n      <td>DARKNESS</td>\n      <td>PARKED MOTOR VEHICLE</td>\n      <td>ONE-WAY</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>41.883685</td>\n      <td>-87.710043</td>\n      <td>POINT (-87.710042988194 41.883684713555)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>JC101797</td>\n      <td>NaN</td>\n      <td>12/31/2018 11:58:00 PM</td>\n      <td>30</td>\n      <td>TRAFFIC SIGNAL</td>\n      <td>FUNCTIONING PROPERLY</td>\n      <td>UNKNOWN</td>\n      <td>DARKNESS, LIGHTED ROAD</td>\n      <td>TURNING</td>\n      <td>NOT DIVIDED</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>23</td>\n      <td>2</td>\n      <td>12</td>\n      <td>41.884754</td>\n      <td>-87.711230</td>\n      <td>POINT (-87.711229788593 41.884753676395)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>JC100021</td>\n      <td>NaN</td>\n      <td>12/31/2018 11:55:00 PM</td>\n      <td>30</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>CLEAR</td>\n      <td>DARKNESS, LIGHTED ROAD</td>\n      <td>SIDESWIPE SAME DIRECTION</td>\n      <td>NOT DIVIDED</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>23</td>\n      <td>2</td>\n      <td>12</td>\n      <td>41.660397</td>\n      <td>-87.618035</td>\n      <td>POINT (-87.618034685178 41.660397249396)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>JC100053</td>\n      <td>NaN</td>\n      <td>12/31/2018 11:53:00 PM</td>\n      <td>35</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>CLEAR</td>\n      <td>DARKNESS, LIGHTED ROAD</td>\n      <td>SIDESWIPE SAME DIRECTION</td>\n      <td>DIVIDED - W/MEDIAN (NOT RAISED)</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>23</td>\n      <td>2</td>\n      <td>12</td>\n      <td>41.873324</td>\n      <td>-87.616936</td>\n      <td>POINT (-87.616936372647 41.873324106032)</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 48 columns</p>\n</div>",
      "text/plain": "      RD_NO CRASH_DATE_EST_I              CRASH_DATE  POSTED_SPEED_LIMIT  \\\n0  JC111663              NaN  01/01/2019 12:00:00 AM                  35   \n1  JC100635                Y  01/01/2019 12:00:00 AM                  30   \n2  JC101797              NaN  12/31/2018 11:58:00 PM                  30   \n3  JC100021              NaN  12/31/2018 11:55:00 PM                  30   \n4  JC100053              NaN  12/31/2018 11:53:00 PM                  35   \n\n  TRAFFIC_CONTROL_DEVICE      DEVICE_CONDITION WEATHER_CONDITION  \\\n0            NO CONTROLS           NO CONTROLS           UNKNOWN   \n1            NO CONTROLS           NO CONTROLS             CLEAR   \n2         TRAFFIC SIGNAL  FUNCTIONING PROPERLY           UNKNOWN   \n3            NO CONTROLS           NO CONTROLS             CLEAR   \n4            NO CONTROLS           NO CONTROLS             CLEAR   \n\n       LIGHTING_CONDITION          FIRST_CRASH_TYPE  \\\n0                 UNKNOWN      PARKED MOTOR VEHICLE   \n1                DARKNESS      PARKED MOTOR VEHICLE   \n2  DARKNESS, LIGHTED ROAD                   TURNING   \n3  DARKNESS, LIGHTED ROAD  SIDESWIPE SAME DIRECTION   \n4  DARKNESS, LIGHTED ROAD  SIDESWIPE SAME DIRECTION   \n\n                   TRAFFICWAY_TYPE  ...  INJURIES_NON_INCAPACITATING  \\\n0                      NOT DIVIDED  ...                          0.0   \n1                          ONE-WAY  ...                          0.0   \n2                      NOT DIVIDED  ...                          0.0   \n3                      NOT DIVIDED  ...                          0.0   \n4  DIVIDED - W/MEDIAN (NOT RAISED)  ...                          0.0   \n\n  INJURIES_REPORTED_NOT_EVIDENT INJURIES_NO_INDICATION INJURIES_UNKNOWN  \\\n0                           0.0                    1.0              0.0   \n1                           0.0                    1.0              0.0   \n2                           0.0                    3.0              0.0   \n3                           0.0                    2.0              0.0   \n4                           0.0                    2.0              0.0   \n\n  CRASH_HOUR CRASH_DAY_OF_WEEK CRASH_MONTH   LATITUDE  LONGITUDE  \\\n0          0                 3           1  41.793502 -87.586407   \n1          0                 3           1  41.883685 -87.710043   \n2         23                 2          12  41.884754 -87.711230   \n3         23                 2          12  41.660397 -87.618035   \n4         23                 2          12  41.873324 -87.616936   \n\n                                   LOCATION  \n0  POINT (-87.586406738035 41.793502271093)  \n1  POINT (-87.710042988194 41.883684713555)  \n2  POINT (-87.711229788593 41.884753676395)  \n3  POINT (-87.618034685178 41.660397249396)  \n4  POINT (-87.616936372647 41.873324106032)  \n\n[5 rows x 48 columns]"
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_con.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_first_row(df, grouping_columns):\n",
    "    \"\"\"Group rows for the grouping columns and return the first row belonging to each group\n",
    "    (you can look at first() for reference). We'll write this function to be more general in case\n",
    "    we want to use it for a different resample.\n",
    "    return a dataframe without a hierarchical index (use default index)\n",
    "    \n",
    "    See the example link below if you want a better sense of what this should return\n",
    "    \"\"\"\n",
    "    grouping = df.groupby(grouping_columns,as_index = False).first()\n",
    "    return grouping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MONTH'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-239-9f8fff7da7b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test your code, we want segment_rows to be resampled version of hist_con where we've grouped by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# properties month, day_of_week, hour, and segment_id and returned the first measure of each group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msegment_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_group_first_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_con\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'MONTH'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DAY_OF_WEEK'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HOUR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SEGMENT_ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msegment_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-238-320a9c2ea5d3>\u001b[0m in \u001b[0;36mget_group_first_row\u001b[0;34m(df, grouping_columns)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexample\u001b[0m \u001b[0mlink\u001b[0m \u001b[0mbelow\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwant\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbetter\u001b[0m \u001b[0msense\u001b[0m \u001b[0mof\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mshould\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgrouping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouping_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mas_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrouping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[1;32m   7892\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7893\u001b[0m             \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7894\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7895\u001b[0m         )\n\u001b[1;32m   7896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   2520\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2522\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mmutated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             )\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MONTH'"
     ]
    }
   ],
   "source": [
    "# test your code, we want segment_rows to be resampled version of hist_con where we've grouped by the\n",
    "# properties month, day_of_week, hour, and segment_id and returned the first measure of each group\n",
    "segment_rows = get_group_first_row(hist_con, ['MONTH','DAY_OF_WEEK', 'HOUR', 'SEGMENT_ID'])\n",
    "segment_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table should look something like [this](assets/segment_rows.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Basic Bar Chart Visualization (10 points)\n",
    "We want to create a visualization for the *average speed* of each segment (across all the samples). To do this, we're going to want to group by each segment and calculate the average speed on each. Complete this code on the `average_speed_per_segment` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_speed_per_segment(df):\n",
    "    \"\"\"Group rows by SEGMENT_ID and calculate the mean of each\n",
    "    return a series where the index is the segment id and each value is the average speed per segment\n",
    "    \"\"\"\n",
    "    return df.groupby(\"SEGMENT_ID\").SPEED.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_speed = average_speed_per_segment(segment_rows)\n",
    "average_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average speed per segment\n",
    "average_speed = average_speed_per_segment(segment_rows)\n",
    "\n",
    "# create labels for the visualization\n",
    "labels = average_speed.index.astype(str)\n",
    "\n",
    "# grab the values from the table\n",
    "values = pd.DataFrame(average_speed).reset_index()\n",
    "\n",
    "# create a chart\n",
    "base = alt.Chart(values)\n",
    "\n",
    "# we're going to \"encode\" the variables, more on this next assignment\n",
    "encoding = base.encode(\n",
    "    x= alt.X(\n",
    "            'SEGMENT_ID:Q',\n",
    "            title='Segment ID',\n",
    "            scale=alt.Scale(zero=False)\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "            'sum(SPEED):Q',\n",
    "            title='Speed Average MPH'\n",
    "    ),\n",
    ")\n",
    "\n",
    "# we're going to use a bar chart and set various parameters (like bar size and title) to make it readable\n",
    "encoding.mark_bar(size=7).properties(title='Average Speed per Segment',height=300, width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table should look something like [this](assets/average_speed.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Create a basic pivot table (10 points)\n",
    "For the next visualization, we need a more complex transformation that will allow us to see the average speed for each month. To do this, we will create a pivot table where the index is the month, and each column is a segment id. We will put the average speed in the cells. From the table, we'll be able to find the month (by index)--giving us the row, and pick the column corresponding to the segment we care about.\n",
    "\n",
    "Complete the `create_pivot_table` function for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pivot_table (df):\n",
    "    \"\"\"return a pivot table where:\n",
    "    each row i is a month\n",
    "    each column j is a segment id\n",
    "    each cell value is the average speed for the month i in the segment j\n",
    "    \"\"\"\n",
    "    pivoted = pd.pivot_table(df,index=[\"MONTH\"], values = ['SPEED'], columns=['SEGMENT_ID'],aggfunc= 'mean') \n",
    "    pivoted.columns = pivoted.columns.droplevel()\n",
    "    return pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the code and see what's in the table\n",
    "pivot_table = create_pivot_table(segment_rows)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table should look something like [this](assets/pivot_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're going to implement a transformation to put the pivot table into a 'long form' because it\n",
    "# is easier to specify the visualization. You can print out hm_pivot_table to see what it looks like\n",
    "hm_pivot_table = pivot_table.copy().unstack().reset_index()\n",
    "hm_pivot_table['SPEED'] = hm_pivot_table[0]\n",
    "hm_pivot_table.drop(0,axis=1,inplace=True)\n",
    "\n",
    "# create the visualization. We're going to use rectangles (a heat map of sorts). We'll use the segment_id to\n",
    "# figure out the horizontal placement (x), the month as the vertical (y) and use color to encode the speed.\n",
    "encoding = alt.Chart(hm_pivot_table).mark_rect().encode(\n",
    "    x='SEGMENT_ID:O',\n",
    "    y='MONTH:O',\n",
    "    color='SPEED:Q'\n",
    ")\n",
    "\n",
    "encoding.properties(title='Average Speed per Segment per Month',height=300, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "pivot_table = create_pivot_table(segment_rows)\n",
    "# check that the rows are months and columns are segments\n",
    "assert pivot_table.shape == (11, 78), \"Problem 2.3, first test\"\n",
    "# check that the value is the average\n",
    "assert int(pivot_table.loc[2,19]) == 6, \"Problem 2.3, second test\"\n",
    "assert int(pivot_table.loc[3,19]) == 10, \"Problem 2.3, third test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Sorting, Transforming, and Filtering (20 points)\n",
    "Without telling you too much about the visualization we want to create next (that's part of the bonus below), we need to get the data into a form we can use. \n",
    "- We're going to need to sort the dataframe by one or more columns (this is the `sort` function). \n",
    "- We'll want to create a derivative column that is the time of the measurement rounded to the nearest hour (`time_to_hours`)\n",
    "- We need to \"facet\" the data into groups to generate different visualizations. \n",
    "- We need a function that selects part of the dataframe that matches a specific characteristic (`filter_orientation`)\n",
    "- Grab a specific column from the dataframe (`select_column`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(df, sorting_columns):\n",
    "    \"\"\"Sort the rows by the columns\n",
    "    return the sorted dataframe\n",
    "    \"\"\"\n",
    "    sorted_df = df.sort_values(sorting_columns)\n",
    "    return sorted_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_rows = sort(segment_rows, ['SEGMENT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_hours(df):\n",
    "    \"\"\" Add a column (called TIME_HOURS) based on the data in the TIME column and rounded up \n",
    "    the value to the nearest hour.  For example, if the original TIME row said: \n",
    "    ‘02/28/2018 05:40:00 PM’ we want ‘2018-02-28 18:00:00’  \n",
    "    (the change is that 5:40pm was rounded up to 6:00pm and the TIME_HOUR column is \n",
    "    actually a proper datetime and not a string).\n",
    "    \"\"\"\n",
    "    df['TIME_HOURS']= pd.to_datetime(df['TIME']).dt.round('H') \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_rows = time_to_hours(segment_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_orientation(df, traffic_orientation):\n",
    "    \"\"\" Filter the rows according to the traffic orientation\n",
    "    return a df that is a subset of the original with the desired orientation\n",
    "    \"\"\"\n",
    "    return df[df[\"DIRECTION\"]== traffic_orientation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb = filter_orientation(segment_rows, 'SB')\n",
    "nb = filter_orientation(segment_rows, 'NB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sb table should look something like [this](assets/sb.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_column(df, column_name):\n",
    "    \"\"\" Select a column from the df\n",
    "    return a series with the desired column\n",
    "    \"\"\"\n",
    "    return df[column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're going to remove speeds of -1 (no data)\n",
    "sb = sb[sb.SPEED > -1]\n",
    "nb = nb[nb.SPEED > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "alt.Chart(sb.append(nb)).mark_rect().encode(\n",
    "    x='month(TIME_HOURS):T',\n",
    "    y='FROM_STREET:N',\n",
    "    color='mean(SPEED):Q',\n",
    "    facet='DIRECTION:N'\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=400\n",
    ")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 (Bonus)  Traffic heatmap visualization (up to 2 points)\n",
    "Looking at the visualization above (the one showing Northbound versus Southbound facets), what domain/abstract tasks are fulfilled by this visualization? List at least one domain task and the corresponding abstract task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e2996874b27a42b2dd6b7c869cae5d94",
     "grade": true,
     "grade_id": "complex_heatmap_vis",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Domain task: How does the average speed differ among streets, for both NB and SB throughout the year?<br>\n",
    "Abstract task: What is the average of a quantitative variable across two other variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART B: Crashes (25 points)\n",
    "For parts 2.6 and 2.7 we will use the Crashes dataset. This dataset contains crash entries recording the time of the accident, the street, and the street number where the accident occurred. You will work with accidents recorded on Pulaski Road\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['RD_NO', 'CRASH_DATE_EST_I', 'CRASH_DATE', 'POSTED_SPEED_LIMIT',\n       'TRAFFIC_CONTROL_DEVICE', 'DEVICE_CONDITION', 'WEATHER_CONDITION',\n       'LIGHTING_CONDITION', 'FIRST_CRASH_TYPE', 'TRAFFICWAY_TYPE', 'LANE_CNT',\n       'ALIGNMENT', 'ROADWAY_SURFACE_COND', 'ROAD_DEFECT', 'REPORT_TYPE',\n       'CRASH_TYPE', 'INTERSECTION_RELATED_I', 'NOT_RIGHT_OF_WAY_I',\n       'HIT_AND_RUN_I', 'DAMAGE', 'DATE_POLICE_NOTIFIED',\n       'PRIM_CONTRIBUTORY_CAUSE', 'SEC_CONTRIBUTORY_CAUSE', 'STREET_NO',\n       'STREET_DIRECTION', 'STREET_NAME', 'BEAT_OF_OCCURRENCE',\n       'PHOTOS_TAKEN_I', 'STATEMENTS_TAKEN_I', 'DOORING_I', 'WORK_ZONE_I',\n       'WORK_ZONE_TYPE', 'WORKERS_PRESENT_I', 'NUM_UNITS',\n       'MOST_SEVERE_INJURY', 'INJURIES_TOTAL', 'INJURIES_FATAL',\n       'INJURIES_INCAPACITATING', 'INJURIES_NON_INCAPACITATING',\n       'INJURIES_REPORTED_NOT_EVIDENT', 'INJURIES_NO_INDICATION',\n       'INJURIES_UNKNOWN', 'CRASH_HOUR', 'CRASH_DAY_OF_WEEK', 'CRASH_MONTH',\n       'LATITUDE', 'LONGITUDE', 'LOCATION'],\n      dtype='object')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "crashes = pd.read_csv('/home/tony/Desktop/github_repos/Dataquest-modules/utf-8Traffic.Crashes.csv.gz')\n",
    "crashes_pulaski = crashes[crashes.STREET_NAME == 'PULASKI RD']\n",
    "# Relevant column names: 'STREET_DIRECTION','INJURIES_TOTAL\n",
    "crashes_pulaski.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RD_NO</th>\n      <th>CRASH_DATE_EST_I</th>\n      <th>CRASH_DATE</th>\n      <th>POSTED_SPEED_LIMIT</th>\n      <th>TRAFFIC_CONTROL_DEVICE</th>\n      <th>DEVICE_CONDITION</th>\n      <th>WEATHER_CONDITION</th>\n      <th>LIGHTING_CONDITION</th>\n      <th>FIRST_CRASH_TYPE</th>\n      <th>TRAFFICWAY_TYPE</th>\n      <th>...</th>\n      <th>INJURIES_NON_INCAPACITATING</th>\n      <th>INJURIES_REPORTED_NOT_EVIDENT</th>\n      <th>INJURIES_NO_INDICATION</th>\n      <th>INJURIES_UNKNOWN</th>\n      <th>CRASH_HOUR</th>\n      <th>CRASH_DAY_OF_WEEK</th>\n      <th>CRASH_MONTH</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>LOCATION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>JC100005</td>\n      <td>NaN</td>\n      <td>12/31/2018 11:45:00 PM</td>\n      <td>25</td>\n      <td>TRAFFIC SIGNAL</td>\n      <td>FUNCTIONING PROPERLY</td>\n      <td>UNKNOWN</td>\n      <td>DARKNESS, LIGHTED ROAD</td>\n      <td>TURNING</td>\n      <td>NOT DIVIDED</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>23</td>\n      <td>2</td>\n      <td>12</td>\n      <td>41.851521</td>\n      <td>-87.724905</td>\n      <td>POINT (-87.72490478675 41.851521442331)</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>JB574321</td>\n      <td>NaN</td>\n      <td>12/31/2018 09:20:00 PM</td>\n      <td>30</td>\n      <td>TRAFFIC SIGNAL</td>\n      <td>FUNCTIONING PROPERLY</td>\n      <td>RAIN</td>\n      <td>DARKNESS, LIGHTED ROAD</td>\n      <td>REAR END</td>\n      <td>NOT DIVIDED</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>21</td>\n      <td>2</td>\n      <td>12</td>\n      <td>41.807977</td>\n      <td>-87.723443</td>\n      <td>POINT (-87.723442855227 41.807977202659)</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>JB574112</td>\n      <td>NaN</td>\n      <td>12/31/2018 05:30:00 PM</td>\n      <td>30</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>RAIN</td>\n      <td>DARKNESS, LIGHTED ROAD</td>\n      <td>PARKED MOTOR VEHICLE</td>\n      <td>PARKING LOT</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>17</td>\n      <td>2</td>\n      <td>12</td>\n      <td>41.799320</td>\n      <td>-87.723191</td>\n      <td>POINT (-87.72319071101 41.799320431921)</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>JC111739</td>\n      <td>NaN</td>\n      <td>12/31/2018 05:30:00 PM</td>\n      <td>30</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>RAIN</td>\n      <td>DUSK</td>\n      <td>REAR END</td>\n      <td>NOT DIVIDED</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>17</td>\n      <td>2</td>\n      <td>12</td>\n      <td>41.822564</td>\n      <td>-87.724187</td>\n      <td>POINT (-87.724187479133 41.822563835982)</td>\n    </tr>\n    <tr>\n      <th>240</th>\n      <td>JB573809</td>\n      <td>NaN</td>\n      <td>12/31/2018 01:30:00 PM</td>\n      <td>30</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>RAIN</td>\n      <td>DAYLIGHT</td>\n      <td>TURNING</td>\n      <td>DIVIDED - W/MEDIAN (NOT RAISED)</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>13</td>\n      <td>2</td>\n      <td>12</td>\n      <td>41.796759</td>\n      <td>-87.723116</td>\n      <td>POINT (-87.723115903434 41.79675909896)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>118084</th>\n      <td>JB100805</td>\n      <td>NaN</td>\n      <td>01/01/2018 02:18:00 PM</td>\n      <td>30</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>CLEAR</td>\n      <td>DAYLIGHT</td>\n      <td>PARKED MOTOR VEHICLE</td>\n      <td>NOT DIVIDED</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>14</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41.857197</td>\n      <td>-87.724759</td>\n      <td>POINT (-87.724758888494 41.857196541155)</td>\n    </tr>\n    <tr>\n      <th>118103</th>\n      <td>JB100649</td>\n      <td>NaN</td>\n      <td>01/01/2018 01:15:00 PM</td>\n      <td>30</td>\n      <td>NO CONTROLS</td>\n      <td>NO CONTROLS</td>\n      <td>CLEAR</td>\n      <td>DAYLIGHT</td>\n      <td>TURNING</td>\n      <td>NOT DIVIDED</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>13</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41.866229</td>\n      <td>-87.725031</td>\n      <td>POINT (-87.725030704501 41.866228698469)</td>\n    </tr>\n    <tr>\n      <th>118148</th>\n      <td>JB100673</td>\n      <td>NaN</td>\n      <td>01/01/2018 09:15:00 AM</td>\n      <td>30</td>\n      <td>TRAFFIC SIGNAL</td>\n      <td>FUNCTIONING PROPERLY</td>\n      <td>CLEAR</td>\n      <td>DAYLIGHT</td>\n      <td>REAR END</td>\n      <td>NOT DIVIDED</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41.880614</td>\n      <td>-87.725521</td>\n      <td>POINT (-87.725520995356 41.880613596041)</td>\n    </tr>\n    <tr>\n      <th>118206</th>\n      <td>JB100213</td>\n      <td>NaN</td>\n      <td>01/01/2018 03:24:00 AM</td>\n      <td>30</td>\n      <td>NO CONTROLS</td>\n      <td>FUNCTIONING PROPERLY</td>\n      <td>CLEAR</td>\n      <td>DARKNESS, LIGHTED ROAD</td>\n      <td>FIXED OBJECT</td>\n      <td>NOT DIVIDED</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41.864907</td>\n      <td>-87.724984</td>\n      <td>POINT (-87.724983890234 41.864907155372)</td>\n    </tr>\n    <tr>\n      <th>118219</th>\n      <td>JB100186</td>\n      <td>NaN</td>\n      <td>01/01/2018 02:55:00 AM</td>\n      <td>30</td>\n      <td>STOP SIGN/FLASHER</td>\n      <td>FUNCTIONING PROPERLY</td>\n      <td>CLEAR</td>\n      <td>DARKNESS, LIGHTED ROAD</td>\n      <td>REAR END</td>\n      <td>NOT DIVIDED</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41.918891</td>\n      <td>-87.726465</td>\n      <td>POINT (-87.726465314987 41.91889126394)</td>\n    </tr>\n  </tbody>\n</table>\n<p>2826 rows × 48 columns</p>\n</div>",
      "text/plain": "           RD_NO CRASH_DATE_EST_I              CRASH_DATE  POSTED_SPEED_LIMIT  \\\n6       JC100005              NaN  12/31/2018 11:45:00 PM                  25   \n51      JB574321              NaN  12/31/2018 09:20:00 PM                  30   \n126     JB574112              NaN  12/31/2018 05:30:00 PM                  30   \n133     JC111739              NaN  12/31/2018 05:30:00 PM                  30   \n240     JB573809              NaN  12/31/2018 01:30:00 PM                  30   \n...          ...              ...                     ...                 ...   \n118084  JB100805              NaN  01/01/2018 02:18:00 PM                  30   \n118103  JB100649              NaN  01/01/2018 01:15:00 PM                  30   \n118148  JB100673              NaN  01/01/2018 09:15:00 AM                  30   \n118206  JB100213              NaN  01/01/2018 03:24:00 AM                  30   \n118219  JB100186              NaN  01/01/2018 02:55:00 AM                  30   \n\n       TRAFFIC_CONTROL_DEVICE      DEVICE_CONDITION WEATHER_CONDITION  \\\n6              TRAFFIC SIGNAL  FUNCTIONING PROPERLY           UNKNOWN   \n51             TRAFFIC SIGNAL  FUNCTIONING PROPERLY              RAIN   \n126               NO CONTROLS           NO CONTROLS              RAIN   \n133               NO CONTROLS           NO CONTROLS              RAIN   \n240               NO CONTROLS           NO CONTROLS              RAIN   \n...                       ...                   ...               ...   \n118084            NO CONTROLS           NO CONTROLS             CLEAR   \n118103            NO CONTROLS           NO CONTROLS             CLEAR   \n118148         TRAFFIC SIGNAL  FUNCTIONING PROPERLY             CLEAR   \n118206            NO CONTROLS  FUNCTIONING PROPERLY             CLEAR   \n118219      STOP SIGN/FLASHER  FUNCTIONING PROPERLY             CLEAR   \n\n            LIGHTING_CONDITION      FIRST_CRASH_TYPE  \\\n6       DARKNESS, LIGHTED ROAD               TURNING   \n51      DARKNESS, LIGHTED ROAD              REAR END   \n126     DARKNESS, LIGHTED ROAD  PARKED MOTOR VEHICLE   \n133                       DUSK              REAR END   \n240                   DAYLIGHT               TURNING   \n...                        ...                   ...   \n118084                DAYLIGHT  PARKED MOTOR VEHICLE   \n118103                DAYLIGHT               TURNING   \n118148                DAYLIGHT              REAR END   \n118206  DARKNESS, LIGHTED ROAD          FIXED OBJECT   \n118219  DARKNESS, LIGHTED ROAD              REAR END   \n\n                        TRAFFICWAY_TYPE  ...  INJURIES_NON_INCAPACITATING  \\\n6                           NOT DIVIDED  ...                          0.0   \n51                          NOT DIVIDED  ...                          0.0   \n126                         PARKING LOT  ...                          0.0   \n133                         NOT DIVIDED  ...                          0.0   \n240     DIVIDED - W/MEDIAN (NOT RAISED)  ...                          0.0   \n...                                 ...  ...                          ...   \n118084                      NOT DIVIDED  ...                          0.0   \n118103                      NOT DIVIDED  ...                          0.0   \n118148                      NOT DIVIDED  ...                          2.0   \n118206                      NOT DIVIDED  ...                          1.0   \n118219                      NOT DIVIDED  ...                          0.0   \n\n       INJURIES_REPORTED_NOT_EVIDENT INJURIES_NO_INDICATION INJURIES_UNKNOWN  \\\n6                                0.0                    3.0              0.0   \n51                               0.0                    2.0              0.0   \n126                              0.0                    2.0              0.0   \n133                              0.0                    4.0              0.0   \n240                              0.0                    6.0              0.0   \n...                              ...                    ...              ...   \n118084                           0.0                    1.0              0.0   \n118103                           0.0                    2.0              0.0   \n118148                           0.0                    3.0              0.0   \n118206                           0.0                    2.0              0.0   \n118219                           0.0                    3.0              0.0   \n\n       CRASH_HOUR CRASH_DAY_OF_WEEK CRASH_MONTH   LATITUDE  LONGITUDE  \\\n6              23                 2          12  41.851521 -87.724905   \n51             21                 2          12  41.807977 -87.723443   \n126            17                 2          12  41.799320 -87.723191   \n133            17                 2          12  41.822564 -87.724187   \n240            13                 2          12  41.796759 -87.723116   \n...           ...               ...         ...        ...        ...   \n118084         14                 2           1  41.857197 -87.724759   \n118103         13                 2           1  41.866229 -87.725031   \n118148          9                 2           1  41.880614 -87.725521   \n118206          3                 2           1  41.864907 -87.724984   \n118219          2                 2           1  41.918891 -87.726465   \n\n                                        LOCATION  \n6        POINT (-87.72490478675 41.851521442331)  \n51      POINT (-87.723442855227 41.807977202659)  \n126      POINT (-87.72319071101 41.799320431921)  \n133     POINT (-87.724187479133 41.822563835982)  \n240      POINT (-87.723115903434 41.79675909896)  \n...                                          ...  \n118084  POINT (-87.724758888494 41.857196541155)  \n118103  POINT (-87.725030704501 41.866228698469)  \n118148  POINT (-87.725520995356 41.880613596041)  \n118206  POINT (-87.724983890234 41.864907155372)  \n118219   POINT (-87.726465314987 41.91889126394)  \n\n[2826 rows x 48 columns]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "crashes_pulaski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Calculate summary statistics for grouped streets (15 points)\n",
    "- Group the streets every 300 units (street numbers). Hint: You can use the `pd.cut` function\n",
    "- Calculate the number of accidents (count rows) and the total of injuries (sum injuries total) for each of these 300-chunk road segments. Do this *for each direction*.\n",
    "\n",
    "Complete bin_crashes and calculate_group_aggregates functions for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_crashes(df):\n",
    "    \"\"\" Assign each crash instance a category (bin) every 300 house number units starting from 0\n",
    "    Return a new dataframe with a column called BIN where each value is the start of the bin\n",
    "    i.e. 0 is the label for records with street number n, such that 1 <= n <= 300\n",
    "    300 is the label for records with with n at 301 <= n <= 600, and so on.\n",
    "    x, bins, right: bool = True, labels=None, retbins: bool = False, precision: int = 3, \n",
    "     include_lowest: bool = False, duplicates: str = 'raise\n",
    "    \"\"\"\n",
    "    bins= list(range(0,14000,300))\n",
    "    df['BIN']= pd.cut(df['STREET_NO'], bins= bins)\n",
    "    df['BIN'] =df['BIN'].astype(str)\n",
    "    def mod(s):\n",
    "        split1 = s.strip(\"(]\").split(\",\")[0]\n",
    "        return int(split1)\n",
    "    df['BIN']= df['BIN'].apply(mod)\n",
    "\n",
    "    return df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/tony/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  # Remove the CWD from sys.path while we load stuff.\n/home/tony/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  # This is added back by InteractiveShellApp.init_path()\n/home/tony/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  from ipykernel import kernelapp as app\n"
    }
   ],
   "source": [
    "binned_df = bin_crashes(crashes_pulaski)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample of the relevant columns from the table would look something like [this](assets/binned_df.png). We can also create a histogram of street numbers to see which are the most prevalent. It should look something like [this](assets/street_no.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9c7c0bbe020d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create this vis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m alt.Chart(binned_df).mark_bar().encode(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0malt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BIN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0malt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alt' is not defined"
     ]
    }
   ],
   "source": [
    "# create this vis\n",
    "alt.Chart(binned_df).mark_bar().encode(\n",
    "    alt.X('BIN'),\n",
    "    alt.Y('count()')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_group_aggregates(df):\n",
    "    \"\"\" \n",
    "    Return a df with the count of accidents in a 'ACCIDENT_COUNT' column and 'INJURIES_SUM'\n",
    "    \"\"\"\n",
    "    df['INJURIES_SUM'] = df.groupby(['BIN',\"STREET_DIRECTION\"], as_index = False)['INJURIES_TOTAL'].transform('sum')\n",
    "    df['ACCIDENT_COUNT']= df.groupby(['BIN',\"STREET_DIRECTION\"], as_index = False)['CRASH_HOUR'].transform('count')\n",
    " \n",
    "      \n",
    "    return df.sort_values(by='BIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binned_df.groupby(['BIN',\"STREET_DIRECTION\"], as_index = False)['INJURIES_TOTAL'].sum()\n",
    "# binned_df.groupby(['BIN',\"STREET_DIRECTION\"], as_index = False)['CRASH_HOUR'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/tony/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"\n/home/tony/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n"
    }
   ],
   "source": [
    "aggregates = calculate_group_aggregates(binned_df)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table should look something like [this](assets/aggregates.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, here's a plot of injuries in the North and South directions based on bin. This may also help you debug your code. Depending on whether you removed N/A or if you hardcoded things, you may see slight differences. Here's what it might  [look like](assets/direction_injuries.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n<div id=\"altair-viz-199e35606c9a4d64bf8fbd376df158d5\"></div>\n<script type=\"text/javascript\">\n  (function(spec, embedOpt){\n    const outputDiv = document.getElementById(\"altair-viz-199e35606c9a4d64bf8fbd376df158d5\");\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function loadScript(lib) {\n      return new Promise(function(resolve, reject) {\n        var s = document.createElement('script');\n        s.src = paths[lib];\n        s.async = true;\n        s.onload = () => resolve(paths[lib]);\n        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n        document.getElementsByTagName(\"head\")[0].appendChild(s);\n      });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else if (typeof vegaEmbed === \"function\") {\n      displayChart(vegaEmbed);\n    } else {\n      loadScript(\"vega\")\n        .then(() => loadScript(\"vega-lite\"))\n        .then(() => loadScript(\"vega-embed\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"url\": \"altair-data-08dc17492516e404cbae07899db68255.json\", \"format\": {\"type\": \"json\"}}, \"mark\": \"point\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"STREET_DIRECTION\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"BIN\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"INJURIES_SUM\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\"}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.Chart(...)"
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(aggregates).mark_point().encode(\n",
    "    alt.Color('STREET_DIRECTION'),\n",
    "    alt.X('BIN'),\n",
    "    alt.Y('INJURIES_SUM')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Sort the street ranges (10 points)\n",
    "- Sort the dataframe so North streets are in descending order and South streets are in ascending order\n",
    "- You are provided with a 'sort' arrray that contains this desired order. Use a categorical (pd.Categorial) column to order the dataframe according to this array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['BIN'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bf51396525c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrashes_pulaski\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'STREET_NO'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'STREET_DIRECTION'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BIN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/github_repos/Dataquest-modules/venv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['BIN'] not in index\""
     ]
    }
   ],
   "source": [
    "crashes_pulaski[['STREET_NO','STREET_DIRECTION','BIN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashed_range = list(range(0, crashes_pulaski.STREET_NO.max()+1000, 300))\n",
    "sort = ['N ' + str(s) for s in crashed_range[::-1]] + ['S ' + str(s) for s in crashed_range]\n",
    "def categorical_sorting(df, sort):\n",
    "    \"\"\" Create a column called ORDER_LABEL that contains a concatenation of the street direction and the street range\n",
    "    Set the sort order of this column to the provided sort array (the elements of this column should be in the same order\n",
    "    of the array)\n",
    "    Sort the dataframe by this column\n",
    "    \"\"\"\n",
    "    df[df['STREET_DIRECTION'] == 'N'].sort_values(by='BIN',ascending=False)\n",
    "    df[df['STREET_DIRECTION'] == 'S'].sort_values(by='BIN',ascending=True)\n",
    "    df[\"ORDER_LABEL\"]= df['STREET_DIRECTION']+\" \"+ df['BIN'].astype(str)\n",
    "    df.ORDER_LABEL = sort\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['N 12300',\n 'N 12000',\n 'N 11700',\n 'N 11400',\n 'N 11100',\n 'N 10800',\n 'N 10500',\n 'N 10200',\n 'N 9900',\n 'N 9600',\n 'N 9300',\n 'N 9000',\n 'N 8700',\n 'N 8400',\n 'N 8100',\n 'N 7800',\n 'N 7500',\n 'N 7200',\n 'N 6900',\n 'N 6600',\n 'N 6300',\n 'N 6000',\n 'N 5700',\n 'N 5400',\n 'N 5100',\n 'N 4800',\n 'N 4500',\n 'N 4200',\n 'N 3900',\n 'N 3600',\n 'N 3300',\n 'N 3000',\n 'N 2700',\n 'N 2400',\n 'N 2100',\n 'N 1800',\n 'N 1500',\n 'N 1200',\n 'N 900',\n 'N 600',\n 'N 300',\n 'N 0',\n 'S 0',\n 'S 300',\n 'S 600',\n 'S 900',\n 'S 1200',\n 'S 1500',\n 'S 1800',\n 'S 2100',\n 'S 2400',\n 'S 2700',\n 'S 3000',\n 'S 3300',\n 'S 3600',\n 'S 3900',\n 'S 4200',\n 'S 4500',\n 'S 4800',\n 'S 5100',\n 'S 5400',\n 'S 5700',\n 'S 6000',\n 'S 6300',\n 'S 6600',\n 'S 6900',\n 'S 7200',\n 'S 7500',\n 'S 7800',\n 'S 8100',\n 'S 8400',\n 'S 8700',\n 'S 9000',\n 'S 9300',\n 'S 9600',\n 'S 9900',\n 'S 10200',\n 'S 10500',\n 'S 10800',\n 'S 11100',\n 'S 11400',\n 'S 11700',\n 'S 12000',\n 'S 12300']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_groups = categorical_sorting(aggregates, sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table should look something like [this](assets/sorted_groups.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, just for kicks, let's see where injuries happen. We're going to color bars by the bin and preserve our ascending/descending visualization. We can probably imagine other (better) ways to visualize this data, but this may be useful for you to debug. The visualization should look something like [this](assets/order_injuries.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(sorted_groups).mark_bar().encode(\n",
    "    alt.X('ORDER_LABEL:O', sort=sort),\n",
    "    alt.Y('INJURIES_SUM:Q'),\n",
    "    alt.Color('BIN:Q')\n",
    ").properties(\n",
    "    width=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's actually make a useful visualization using some of the dataframes we've created. As a bonus, we're going to ask you what you would use this for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make the kind of chart we are interested in we're going to build it out of three different charts and\n",
    "# put them together at the end\n",
    "\n",
    "# this is going to be the left chart\n",
    "bar_sorted_groups = sorted_groups[['ACCIDENT_COUNT','INJURIES_SUM']].unstack().reset_index() \\\n",
    "    .rename({'level_0':'TYPE','level_1':'SPEED',0:'COUNT'},axis=1)\n",
    "\n",
    "a = alt.Chart(bar_sorted_groups).mark_bar().transform_filter(alt.datum.TYPE == 'ACCIDENT_COUNT').encode(\n",
    "    x=alt.X('COUNT:Q',sort='descending'),\n",
    "    y=alt.Y('SPEED:O',axis=None),\n",
    "    color=alt.Color('TYPE:N', \n",
    "                    legend=None,\n",
    "                    scale=alt.Scale(domain=['ACCIDENT_COUNT', 'INJURIES_SUM'],\n",
    "                                    range=['blue', 'orange']))\n",
    ").properties(\n",
    "    title='ACCIDENT_COUNT',\n",
    "    width=300,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# middle \"chart\" which actually won't be a chart, just a bunch of labels\n",
    "b = alt.Chart(bar_sorted_groups).mark_bar().transform_filter(alt.datum.TYPE == 'ACCIDENT_COUNT').encode(\n",
    "    y=alt.Y('SPEED:O', axis=None),\n",
    "    text=alt.Text('SPEED:Q')\n",
    ").mark_text().properties(title='SPEED',\n",
    "                         width=20,\n",
    "                         height=600)\n",
    "\n",
    "# and the right most chart\n",
    "c = alt.Chart(bar_sorted_groups).mark_bar().transform_filter(alt.datum.TYPE == 'INJURIES_SUM').encode(\n",
    "    x='COUNT:Q',\n",
    "    y=alt.Y('SPEED:O',axis=None),\n",
    "    color=alt.Color('TYPE:N', \n",
    "                    legend=None,\n",
    "                    scale=alt.Scale(domain=['ACCIDENT_COUNT', 'INJURIES_SUM'],\n",
    "                                    range=['blue', 'orange']))\n",
    ").properties(\n",
    "    title='INJURIES_SUM',\n",
    "    width=300,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# put them all together \n",
    "\n",
    "a | b | c\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 (Bonus) Accident barchart visualization (up to 2 points)\n",
    "Looking at the visualization we generated above (part 2.7), what domain/abstract tasks are fulfilled by this visualization? List at least one domain task and the corresponding abstract task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a3474bc13f92c1be420aa3788172be49",
     "grade": true,
     "grade_id": "complex_barchart_vis",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_information_visualization_i_v2_assignment1"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "426px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "none",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}