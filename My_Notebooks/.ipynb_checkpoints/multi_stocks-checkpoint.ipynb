{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File AMEX_20190905.csv does not exist: 'AMEX_20190905.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7ed57b7f6385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'AMEX_20190905.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stock'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'high'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'low'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'close'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'volume'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dividends'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/forXGBoost/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/forXGBoost/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/forXGBoost/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/forXGBoost/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/forXGBoost/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File AMEX_20190905.csv does not exist: 'AMEX_20190905.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "path = r'/home/tony/Desktop/My_repos/Dataquest-modules/excel_files/AMEX_20190905.csv'\n",
    "\n",
    "df = pd.read_csv(path,names=['stock','date','open','high','low','close','volume','dividends'])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:10,'stock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "data = []\n",
    "\n",
    "for i,stock in enumerate(df):\n",
    "    names = yf.Ticker('TSLA')\n",
    "    history = names.history(start='2003-01-01',end='2020-02-01')\n",
    "    names = pd.DataFrame(history)\n",
    "#     names['PCT_Change_Close'] =  names.Close.pct_change()\n",
    "#     names['PCT_Change_Low'] = names.Low.pct_change()\n",
    "#     names['PCT_Change_Open'] = names.Open.pct_change()\n",
    "#     names['PCT_Change_High'] = names.High.pct_change()\n",
    "#     names['PCT_Change_Vol'] = names.Volume.pct_change()\n",
    "    names['Stock'] = stock   \n",
    "    names.drop(names.index[0],inplace=True)\n",
    "    names = names.reset_index()   \n",
    "#     names = names[['Stock','PCT_Change_Close','PCT_Change_Open','PCT_Change_Low','PCT_Change_High','PCT_Change_Vol','Date']]\n",
    "\n",
    "    matrix = []\n",
    "    for i in range(1000):\n",
    "#         days = names.PCT_Change_Close.shift(-i)\n",
    "        days = names.Close.shift(-i)\n",
    "        df = pd.DataFrame({f'Days_{i}':days.values})\n",
    "        matrix.append(df)\n",
    "    matrix = pd.concat(matrix,axis=1)\n",
    "    matrix.insert(loc=0, column='Stock', value=stock)\n",
    "    data.append(matrix)\n",
    "\n",
    "#     names = names[['Stock','Date','PCT_Change_Close']]\n",
    "#     matrix = pd.pivot_table(names,index='Stock',columns='Date',values='PCT_Change_Close')\n",
    "\n",
    "# pd.options.display.float_format = '${:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.drop(stock.index[-999:],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock = stock.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Deciding on Features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# X = stock.loc[:,'Days_1':]\n",
    "# y = stock['Days_0']\n",
    "\n",
    "# X_train = stock.loc['Days_0':'Days_95',:round(stock.shape[1]*.8)]\n",
    "# y_train = stock.loc['Days_95':,:round(stock.shape[1]*.8)]\n",
    "\n",
    "# X_test = stock.loc['Days_0':'Days_95',round(stock.shape[1]*.8):]\n",
    "# y_test= stock.loc['Days_95':,round(stock.shape[1]*.8):]\n",
    "\n",
    "X_train = stock.loc[:round(stock.shape[1]*.8),'Days_0':'Days_998']\n",
    "y_train = stock.loc[:round(stock.shape[1]*.8),'Days_999']\n",
    "\n",
    "X_test = stock.loc[round(stock.shape[1]*.8):,'Days_0':'Days_998']\n",
    "y_test = stock.loc[round(stock.shape[1]*.8):,'Days_999']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Timer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "PARAMETERS={\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'nthread':-1,\n",
    " 'objective':'reg:squarederror',\n",
    " 'eval_metric':'rmse'}\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 700, 1000],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'max_depth': [15,20,25],\n",
    "    'reg_alpha': [1.1, 1.2, 1.3],\n",
    "    'reg_lambda': [1.1, 1.2, 1.3],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "#     'nthread':[-1],\n",
    "    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Splitting data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_train = xgb.DMatrix(X_train.apply(pd.to_numeric), y_train.apply(pd.to_numeric),nthread=-1)\n",
    "data_test = xgb.DMatrix(X_test.apply(pd.to_numeric), y_test.apply(pd.to_numeric),nthread=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ transpose into xgb.booster.Dmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bst = xgb.train(params=PARAMETERS,\n",
    "                dtrain=data_train,\n",
    "                num_boost_round=999,\n",
    "                evals=[(data_test,\"Test\")],\n",
    "                early_stopping_rounds=10,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.eval(data_test,name='eval')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.eval(data_train,name='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.eval_set([(data_test,\"Test\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.eval_set([(data_train,\"Train\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.get_score('',importance_type='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Decision tree/ important features visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(bst,max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# dump = bst.get_dump(with_stats=True)\n",
    "# for tree in dump:\n",
    "#     print(tree)\n",
    "xgb.plot_tree(bst)\n",
    "plt.rcParams['figure.figsize'] = [10,5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## shap summary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(bst)\n",
    "shap_values_XGB_test = explainer.shap_values(X_test)\n",
    "shap_values_XGB_train = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_shap_XGB_test = pd.DataFrame(shap_values_XGB_test)\n",
    "df_shap_XGB_train = pd.DataFrame(shap_values_XGB_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value,shap_values_XGB_test[j],X_test.iloc[[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_XGB_train,X_train,plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value,shap_values_XGB_test,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_XGB_train,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot('Days_998',shap_values_XGB_train,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#inputs = column of interest as string, column for coloring as string, df of our data, SHAP df, \n",
    "#      x postion of the black dot, y position of the black dot\n",
    "def dep_plt(col, color_by, base_actual_df, base_shap_df, overlay_x, overlay_y): \n",
    "    cmap=sns.diverging_palette(260, 10, sep=1, as_cmap=True) #seaborn pallete \n",
    "    f, ax = plt.subplots() \n",
    "    base_actual_df = np.asarray(base_actual_df)\n",
    "    points = ax.scatter(base_actual_df[:,col], base_shap_df[col], c=base_actual_df[:,color_by], s=20, cmap=cmap)\n",
    "    f.colorbar(points).set_label(color_by) \n",
    "    ax.scatter(overlay_x, overlay_y, color='black', s=50) \n",
    "    plt.xlabel(col) \n",
    "    plt.ylabel(\"SHAP value for \" + str(col)) \n",
    "    plt.show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get list of model inputs in order of SHAP importance\n",
    "imp_cols = df_shap_XGB_train.abs().mean().sort_values(ascending=False).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# loop through this list to show top 3 dependency plots\n",
    "for i in range(0, len(imp_cols)):\n",
    "    #plot the top var and color by the 2nd var\n",
    "    if i == 0 : \n",
    "        dep_plt(imp_cols[i],  \n",
    "        imp_cols[i+1],  \n",
    "        X_train,  \n",
    "        df_shap_XGB_train, \n",
    "        X_test.iloc[j,:][imp_cols[i]], \n",
    "        df_shap_XGB_test.iloc[j,:][imp_cols[i]])\n",
    "\n",
    "     #plot the 2nd and 3rd vars and color by the top var \n",
    "    if (i > 0) and (i < 3):  \n",
    "        dep_plt(imp_cols[i],  \n",
    "        imp_cols[0], X_train,  \n",
    "        df_shap_XGB_train, \n",
    "        X_test.iloc[j,:][imp_cols[i]],  \n",
    "        df_shap_XGB_test.iloc[j,:][imp_cols[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## initial predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "initial_predict = bst.predict(data_test,pred_leaf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "initial_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ set maximum num_boost_round node iterations, but set early_stopping_rounds at 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Using XGBoost CV\n",
    "+ set params\n",
    "+ set dtrain\n",
    "+ use large number of num_boost_round and count on early_stopping_rounds to find optimal number of rounds before reaching the maximum\n",
    "+ seed similar to train_test_splits random_state, but for running cross validation states because each train and each split is designated randomly by computer\n",
    "+ number of folds in CV\n",
    "+ set metrics used for scoring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cv_results = xgb.cv(\n",
    "    PARAMETERS,\n",
    "    data_train,\n",
    "    num_boost_round=999,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    early_stopping_rounds=10,\n",
    "    as_pandas=True,\n",
    ")\n",
    "print(\"cv results{}\".format(cv_results))\n",
    "print(f\"best RSME score with cv :{cv_results['test-rmse-mean'].min()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ cv return table where rows correspond number of boosting trees used\n",
    "+ 4 columns correspond to mean and standard deviation for both train and test\n",
    "+ goal in cv to optimize scoring for eval_metric param during cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Optimize max_depth and min_child_weight\n",
    "+ max_depth is maximum number of nodes allowed from root to the farthest leaf of a tree. Deeper trees can model more complex relationships by adding more nodes, but as we go deeper, splits become less relevant and are sometiems only due to noise, causing model to overfit.\n",
    "+ min_child_weight is the minimum weight(or of samples if all samples have a weight of 1) required in order to create a new node in the tree. A small min_child_weight allows the alogorithm to create children that corresponds to fewer samples, thus allowing for more complex trees, but again more likely to overfit.\n",
    "+ important to tune together to find good trade-off between model bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "can try wider intervals with larger step between each value then narrow it down.\n",
    "\n",
    "better try that myself to find optimal ranges\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "gridsearch_params = [\n",
    "    (max_depth,min_child_weight)\n",
    "    for max_depth in range(9,13)\n",
    "    for min_child_weight in range(5,8)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ make list containing all combinations of max_depth/min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "min_rmse = float(\"Inf\")\n",
    "best_depth = None\n",
    "\n",
    "for max_depth,min_child_weight in gridsearch_params:\n",
    "    print(f\"CV with max_depth={max_depth}, min_child_weight={min_child_weight}\")\n",
    "\n",
    "    PARAMETERS['max_depth'] = max_depth\n",
    "    PARAMETERS['min_child_weight'] = min_child_weight\n",
    "\n",
    "    cv_results = xgb.cv(\n",
    "        PARAMETERS,\n",
    "        data_train,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10,\n",
    "        as_pandas=True\n",
    "    )\n",
    "\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(f\"\\tRMSE {mean_rmse} for {boost_rounds}\")\n",
    "\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_depth = (max_depth,min_child_weight)\n",
    "\n",
    "print(f\"Best params: {best_depth[0]}, {best_depth[1]}, RMSE: {min_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ assign min rmse to infinite\n",
    "+ loop through gridseach params(need to find custom optimal intervals from wide range then narrow down)\n",
    "+ print current max_depth and min_child_weight iteration\n",
    "+ update max_depth, min_child_weight to params\n",
    "+ run cross validation for current iteration of max_depth,min_child_weight\n",
    "+ aggregate test-rmse-mean minimum value and positional index of that value in array\n",
    "+ print optimal scoring in array rounds per iteration\n",
    "+ if current iteration of mean_rmse is less than previous iteration of mean_rmse, aggregate as min_rmse\n",
    "+ print best params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Optimize for subsample and colsample_bytree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ these are parameters that control the sampling of dataset done at each boosting round\n",
    "+ thus can build tree on slightly different data at each step making it less likely to overfit to any single sample or feature\n",
    "+ subsample corresponds to the fraction of observations (the rows) to subsample at each step. default 1, meaning all rows.\n",
    "+ colsample_bytree corresponds to fraction of features(the columns) to use. default is 1, meaning all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_samples = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(subsample,colsample)) # We update our parameters\n",
    "\n",
    "    PARAMETERS['subsample'] = subsample\n",
    "    PARAMETERS['colsample_bytree'] = colsample    # Run CV\n",
    "\n",
    "    cv_results = xgb.cv(\n",
    "        PARAMETERS,\n",
    "        data_train,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10,\n",
    "        as_pandas=True\n",
    "    )    # Update best score\n",
    "\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_samples = (subsample,colsample)\n",
    "        \n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_samples[0], best_samples[1], min_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ assign min rmse to infinite\n",
    "+ We start by the largest values and go down to the smallest\n",
    "+ print current subsample and colsample iteration\n",
    "+ update subsample, colsample to params\n",
    "+ run cross validation for current iteration of subsample, colsample\n",
    "+ aggregate test-rmse-mean minimum value and positional index of that value in array\n",
    "+ print optimal scoring in array rounds per iteration\n",
    "+ if current iteration of mean_rmse is less than previous iteration of mean_rmse, aggregate as min_rmse\n",
    "+ print best params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Find best params for Learning rate (eta)\n",
    "+ corresponds to the shrinkage of weights associated to features after each round, in other words it defines the amount of \"correction\" we make at each step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_eta = None\n",
    "\n",
    "for eta in [.3,.2,.1,.05,.01,.005]:\n",
    "    print(f\"CV with eta={eta}\")\n",
    "\n",
    "    PARAMETERS['eta'] = eta\n",
    "    cv_results = xgb.cv(\n",
    "        PARAMETERS,\n",
    "        data_train,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10,\n",
    "        as_pandas=True\n",
    "    )\n",
    "\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(f\"\\tRMSE {mean_rmse} for {boost_rounds}\")\n",
    "\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_eta = eta\n",
    "\n",
    "print(f\"Best params: {best_eta}, RSME: {min_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ assign min rmse to infinite\n",
    "+ loop through conventional learning rate (eta)\n",
    "+ print current eta iteration\n",
    "+ update eta to params\n",
    "+ run cross validation for current iteration of eta\n",
    "+ aggregate test-rmse-mean minimum value and positional index of that value in array\n",
    "+  print optimal scoring in array rounds per iteration\n",
    "+ if current iteration of mean_rmse is less than previous iteration of mean_rmse, aggregate as min_rmse\n",
    "+ print best params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ training and best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': best_depth[0],\n",
    "    'min_child_weight': best_depth[1],\n",
    "    'eta': best_eta,\n",
    "    'subsample': best_samples[0],\n",
    "    'colsample_bytree': best_samples[1],\n",
    "    'objective':'reg:squarederror',\n",
    "    'eval_metric':'rmse',\n",
    "    'nthread':-1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ optimal parameters for xgboost API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    data_train,\n",
    "    num_boost_round=999,\n",
    "    evals=[(data_test,\"Test\")],\n",
    "    early_stopping_rounds=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Best RMSE: {:.2f} in {} rounds\".format(model.best_score,model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ if early stopping occurs, the model will have three additional fields .best_score, .best_iteration, and .best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_boost_round = model.best_iteration + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ allow for model best_iteration inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_model = xgb.train(\n",
    "    params,\n",
    "    data_train,\n",
    "    num_boost_round = num_boost_round,\n",
    "    evals=[(data_test,\"Test\")]\n",
    "        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ train data with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# trainleaf = best_model.predict(data_train,pred_leaf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "testleaf = best_model.predict(data_test,pred_leaf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "testleaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = best_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'My Xgboost model came up with these predictions for {final_predictions} for days 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Multi Variate Normal Distribution Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tree_pandas = []\n",
    "tree_numpy = []\n",
    "for column in range(max([len(x) for x in testleaf])):\n",
    "    tree = []\n",
    "    for row in testleaf[:,column]:\n",
    "        lst = [0] * testleaf[:,column].max()\n",
    "        try:\n",
    "            lst[row-1] = 1\n",
    "            tree.append(lst)\n",
    "        except IndexError:\n",
    "            pass\n",
    "    stats = np.asarray(tree)\n",
    "    tree_numpy.append(stats)\n",
    "    df = pd.DataFrame(tree)\n",
    "    df.columns = [f'T{column+1}L{i+1}' for i in df.columns]\n",
    "    df = df.loc[:, (df != 0).any(axis=0)]\n",
    "    # df.reset_index(inplace=True)\n",
    "    tree_pandas.append(df)\n",
    "\n",
    "matrix = pd.concat(tree_pandas,axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_model.save_model(\"xgbregression.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(\"xgbregression.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.eval(data_test,name='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.eval(data_train,name='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_model.eval_set([(data_test,\"Test\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.eval_set([(data_train,\"Train\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.get_score('',importance_type='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Decision Tree/ Feature Importance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(loaded_model,max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb.plot_tree(loaded_model,num_trees=0)\n",
    "plt.rcParams['figure.figsize'] = [10,5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions_API = loaded_model.predict(data_test,pred_leaf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "best_explainer = shap.TreeExplainer(loaded_model)\n",
    "best_shap_values_XGB_test = best_explainer.shap_values(X_test)\n",
    "best_shap_values_XGB_train = best_explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_df_shap_XGB_test = pd.DataFrame(best_shap_values_XGB_test)\n",
    "best_df_shap_XGB_train = pd.DataFrame(best_shap_values_XGB_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.force_plot(best_explainer.expected_value,best_shap_values_XGB_test[j],X_test.iloc[[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.force_plot(best_explainer.expected_value,best_shap_values_XGB_test,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(best_shap_values_XGB_train,X_train,plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(best_shap_values_XGB_train,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot('Days_998',shap_values_XGB_train,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get list of model inputs in order of SHAP importance\n",
    "imp_cols = df_shap_XGB_train.abs().mean().sort_values(ascending=False).index.tolist()\n",
    " \n",
    "# loop through this list to show top 3 dependency plots\n",
    "for i in range(0, len(imp_cols)):\n",
    "    #plot the top var and color by the 2nd var\n",
    "    if i == 0 :  \n",
    "        dep_plt(imp_cols[i],  \n",
    "        imp_cols[i+1],  \n",
    "        X_train,  \n",
    "        df_shap_XGB_train, \n",
    "        X_test.iloc[j,:][imp_cols[i]], \n",
    "        df_shap_XGB_test.iloc[j,:][imp_cols[i]]) \n",
    "     #plot the 2nd and 3rd vars and color by the top var\n",
    "    if (i > 0) and (i < 3) :  \n",
    "        dep_plt(imp_cols[i],  \n",
    "        imp_cols[0],  X_train,  \n",
    "        df_shap_XGB_train, \n",
    "        X_test.iloc[j,:][imp_cols[i]],  \n",
    "        df_shap_XGB_test.iloc[j,:][imp_cols[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## With Sklearn xgboost wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "regressor = XGBRegressor(n_jobs=-1,objective='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "grid = GridSearchCV(regressor,param_grid,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start_time = timer(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ fitting train data to grid search tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# print(r2_score(y_test,grid.best_estimator_.predict(X_test)))\n",
    "print(mean_squared_error(y_test,grid.best_estimator_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ mean sqaured error scoring and root squared scoring available from sklearn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test,pred, color='b')\n",
    "ax.plot([y_test.min(),y_test.max()],[y_test.min(),y_test.max()],'k--',lw=4)\n",
    "ax.set_xlabel('preds')\n",
    "ax.set_ylabel('y_test')\n",
    "ax.set_title('scatter plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ plotting out y_test juxtaposed to preds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ link for sklearn wrapper; https://www.kaggle.com/omarito/gridsearchcv-xgbregressor-0-556-lb\n",
    "+ link for xgboost api; https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['y_test'] = y_test\n",
    "pred['diff'] = pred['y_test'] - pred[0] \n",
    "pred['exp'] = (pred.y_test - pred[0])**2#/(pred.y_test + pred[0])\n",
    "avg_pred = pred.exp.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Manual calculations of mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ Predictions generated from sklearn wraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ manualy calculated mean squared error of regression model from sklearn wrapper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
